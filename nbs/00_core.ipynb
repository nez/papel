{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import arxiv_dl.arxiv_dl\n",
    "from pathlib import Path\n",
    "path = Path(\"/home/nex/Downloads/ArXiv_Papers\")\n",
    "def dl(lista):\n",
    "    for e in lista:\n",
    "        try:\n",
    "            arxiv_dl.arxiv_dl.main(e)\n",
    "        except:\n",
    "            print(\"error downloading: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#59) [Path('/home/nex/Downloads/ArXiv_Papers/2002.04688_fastai_A_Layered_API_for_Deep_Learning.pdf'),Path('/home/nex/Downloads/ArXiv_Papers/2109.04314v3_Variational_Latent-State_GPT_for_Semi-Supervised_Task-Oriented_Dialog_Systems.pdf'),Path('/home/nex/Downloads/ArXiv_Papers/2103.10385v1__Notes.md'),Path('/home/nex/Downloads/ArXiv_Papers/2304.07061v1_DroidBot-GPT_GPT-powered_UI_Automation_for_Android.pdf'),Path('/home/nex/Downloads/ArXiv_Papers/2002.04688v2__Notes.md'),Path('/home/nex/Downloads/ArXiv_Papers/2107.12598v1__Notes.md'),Path('/home/nex/Downloads/ArXiv_Papers/2302.09210v1__Notes.md'),Path('/home/nex/Downloads/ArXiv_Papers/2109.13296v1_TURINGBENCH_A_Benchmark_Environment_for_Turing_Test_in_the_Age_of_Neural_Text_Generation.pdf'),Path('/home/nex/Downloads/ArXiv_Papers/2109.10725v1_Phenomenological_Gravitational_Phase_Transition_Early_and_Late_Modifications.pdf'),Path('/home/nex/Downloads/ArXiv_Papers/2109.13296v1__Notes.md')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import arxiv\n",
    "search = arxiv.Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_papers = search(\"fastai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def results(s):\n",
    "    return list(map(lambda r: r.entry_id, search(s, max_results=100).results()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mRequesting 100 results at offset 0\u001b[0m\n",
      "\u001b[36mRequesting page of results\u001b[0m\n",
      "\u001b[36mGot first page; 100 of 100 results available\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#transformers_papers = search(\"fastai\", max_results= 99)\n",
    "tp = results(\"gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2204.04477v1_FoundationLayerNorm_Scaling_BERT_and_GPT_to_1000_Layers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/1211.4495v2_Reconstruction_of_Inhomogeneous_Conductivities_via_the_Concept_of_Generalized_Polarization_Tensors.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2304.09974v1_SurgicalGPT_End-to-End_Language-Vision_GPT_for_Visual_Question_Answering_in_Surgery.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2112.04521v1_Accessible_fragments_of_generalized_probabilistic_theories_cone_equivalence_and_applications_to_witnessing_nonclassicality.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2302.09210v1_How_Good_Are_GPT_Models_at_Machine_Translation?_A_Comprehensive_Evaluation.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2103.07469v2_General_probabilistic_theories_An_introduction.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2304.11079v1_Academic_Writing_with_GPT-35_Reflections_on_Practices_Efficacy_and_Transparency.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2001.05147v2_Analytical_shape_recovery_of_a_conductivity_inclusion_based_on_Faber_polynomials.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2108.07789v2_Adapting_GPT_GPT-2_and_BERT_Language_Models_for_Speech_Recognition.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/1911.11059v2_Contextuality_of_general_probabilistic_theories.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2109.04314v3_Variational_Latent-State_GPT_for_Semi-Supervised_Task-Oriented_Dialog_Systems.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2110.08152v1_Kronecker_Decomposition_for_GPT_Compression.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/1810.04596v2_Local_Volume_Effects_in_the_Generalized_Pseudopotential_Theory.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2103.10385v1_GPT_Understands_Too.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2106.04338v1_Engines_of_Power_Electricity_AI_and_General-Purpose_Military_Transformations.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2109.10725v1_Phenomenological_Gravitational_Phase_Transition_Early_and_Late_Modifications.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2109.13296v1_TURINGBENCH_A_Benchmark_Environment_for_Turing_Test_in_the_Age_of_Neural_Text_Generation.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2303.16421v1_ChatGPT_is_a_Knowledgeable_but_Inexperienced_Solver_An_Investigation_of_Commonsense_Problem_in_Large_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2304.03208v1_Cerebras-GPT_Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Done] Paper PDF already exists at: \"/home/nex/Downloads/ArXiv_Papers/2304.07061v1_DroidBot-GPT_GPT-powered_UI_Automation_for_Android.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error downloading:  http://arxiv.org/abs/cs/0409007v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1006.1057v1_On_improving_security_of_GPT_cryptosystems.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1806.10055v2_Twisted_Gabidulin_Codes_in_the_GPT_Cryptosystem.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2206.05593v3_Inverse_problem_for_a_planar_conductivity_inclusion.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error downloading:  http://arxiv.org/abs/cs/0612120v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2108.05864v2_Experimentally_bounding_deviations_from_quantum_theory_for_a_photonic_three-level_system_using_theory-agnostic_tomography.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.06762v1_Shall_We_Pretrain_Autoregressive_Language_Models_with_Retrieval?_A_Comprehensive_Study.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.10428v1_GPT-NER_Named_Entity_Recognition_via_Large_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2010.15678v1_On_the_Failure_of_the_Smart_Approach_of_the_GPT_Cryptosystem.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.06794v1_ChatGPT_cites_the_most-cited_articles_and_journals_relying_solely_on_Google_Scholars_citation_counts_As_a_result_AI_may_amplify_the_Matthew_Effect_in_environmental_science.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1907.00151v5_GPT-based_Generation_for_Classical_Chinese_Poetry.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1912.02985v2_Information_transfer_in_generalized_probabilistic_theories_based_on_weak_repeatability.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2006.15437v1_GPT-GNN_Generative_Pre-Training_of_Graph_Neural_Networks.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2203.00249v2_Exploring_and_Adapting_Chinese_GPT_to_Pinyin_Input_Method.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2301.06052v3_T2M-GPT_Generating_Human_Motion_from_Textual_Descriptions_with_Discrete_Representations.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2303.17728v1_Evaluation_of_GPT_and_BERT-based_models_on_identifying_protein-protein_interactions_in_biomedical_text.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.02138v2_Geotechnical_Parrot_Tales_GPT_Harnessing_Large_Language_Models_in_geotechnical_engineering.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.02819v2_GPT_detectors_are_biased_against_non-native_English_writers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.09333v1_BIM-GPT_a_Prompt-Based_Virtual_Assistant_Framework_for_BIM_Information_Retrieval.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.09487v1_A_GPT-Based_Approach_for_Scientometric_Analysis_Exploring_the_Landscape_of_Artificial_Intelligence_Research.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.11872v1_Generation-driven_Contrastive_Self-training_for_Zero-shot_Text_Classification_with_Instruction-tuned_GPT.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1808.06355v1_Deep_learning_deep_change?_Mapping_the_development_of_the_Artificial_Intelligence_General_Purpose_Technology.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1911.10386v2_The_Characterization_of_Noncontextuality_in_the_Framework_of_Generalized_Probabilistic_Theories.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2303.08033v1_Large_Language_Models_GPT_Struggle_to_Answer_Multiple-Choice_Questions_about_Code.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2303.09325v1_Can_Generative_Pre-trained_Transformers_GPT_Pass_Assessments_in_Higher_Education_Programming_Courses?.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2303.10420v1_A_Comprehensive_Capability_Analysis_of_GPT-3_and_GPT-35_Series_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1707.02521v1_Structure_of_Optimal_State_Discrimination_in_Generalized_Probabilistic_Theories.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1911.07828v3_GPT_Conjecture_Understanding_the_Trade-offs_between_Granularity_Performance_and_Timeliness_in_Control-Flow_Integrity.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2005.05442v2_On_the_Generation_of_Medical_Dialogues_for_COVID-19.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2011.06497v3_Incompatibility_in_general_probabilistic_theories_generalized_spectrahedra_and_tensor_norms.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2202.13834v1_Convexity_and_uncertainty_in_operational_quantum_foundations.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2204.06745v1_GPT-NeoX-20B_An_Open-Source_Autoregressive_Language_Model.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2210.17323v2_GPTQ_Accurate_Post-Training_Quantization_for_Generative_Pre-trained_Transformers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2303.10130v4_GPTs_are_GPTs_An_Early_Look_at_the_Labor_Market_Impact_Potential_of_Large_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.05534v2_Distinguishing_ChatGPT-35_-4-generated_and_human-written_papers_through_Japanese_stylometric_analysis.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1006.0386v1_A_Smart_Approach_for_GPT_Cryptosystem_Based_on_Rank_Codes.pdf\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1205.3358v2_Typical_local_measurements_in_generalised_probabilistic_theories_emergence_of_quantum_bipartite_correlations.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1502.07625v1_Developing_Knowledge_States_Technology_and_the_Enhancement_of_National_Statistical_Capacity.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2004.06429v1_Deep_learning_for_Gaussian_process_tomography_model_selection_using_the_ASDEX_Upgrade_SXR_system.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1904.06247v1_Multi-agent_paradoxes_beyond_quantum_theory.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2002.12328v1_Few-shot_Natural_Language_Generation_for_Task-Oriented_Dialog.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2006.05671v1_Entropic_Uncertainty_Relations_in_a_Class_of_Generalized_Probabilistic_Theories.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2009.08636v1_Hierarchical_GPT_with_Congruent_Transformers_for_Multi-Sentence_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2107.00950v1_Investigating_3D_printed_Cartesian_Divers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2109.02102v3_Teaching_Autoregressive_Language_Models_Complex_Tasks_By_Demonstration.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2109.03137v2_NumGPT_Improving_Numeracy_Ability_of_Generative_Pre-trained_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2109.04446v1_Entanglement_and_superposition_are_equivalent_concepts_in_any_physical_theory.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2109.05256v1_Multilingual_Translation_via_Grafting_Pre-trained_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2201.05513v2_Minimal_Object_Characterisations_using_Harmonic_Generalised_Polarizability_Tensors_and_Symmetry_Groups.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2201.12305v1_A_Post-Quantum_Associative_Memory.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2204.01959v1_Data_Augmentation_for_Intent_Classification_with_Off-the-shelf_Large_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2204.10304v1_Exploring_Artificial_Intelligence_as_a_General_Purpose_Technology_with_Patent_Data_--_A_Systematic_Comparison_of_Four_Classification_Approaches.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2205.05862v3_AdaVAE_Exploring_Adaptive_GPT-2s_in_Variational_Auto-Encoders_for_Language_Modeling.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2205.08940v2_Programming_of_channels_in_generalized_probabilistic_theories.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2211.15593v1_GPT-Neo_for_commonsense_reasoning-a_theoretical_and_practical_lens.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2212.07993v1_Combining_Particle_Tracking_with_Electromagnetic_Radiation_Showers_Merging_GPT_and_Geant4_with_Visualization.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2302.07731v3_Combat_AI_With_AI_Counteract_Machine-Generated_Fake_Restaurant_Reviews_on_Social_Media.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2302.14520v1_Large_Language_Models_Are_State-of-the-Art_Evaluators_of_Translation_Quality.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2303.13013v1_GesGPT_Speech_Gesture_Synthesis_With_Text_Parsing_from_GPT.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2304.05511v1_Training_Large_Language_Models_Efficiently_with_Sparsity_and_Dataflow.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error downloading:  http://arxiv.org/abs/cond-mat/0010205v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1009.0605v2_Gaussian_Process_Bandits_for_Tree_Search_Theory_and_Application_to_Planning_in_Discounted_MDPs.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1403.2509v2_Information_and_communication_in_polygon_theories.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1906.08646v1_Fine-tuning_Pre-Trained_Transformer_Language_Models_to_Distantly_Supervised_Relation_Extraction.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2003.00349v4_Self-testing_of_physical_theories_or_is_quantum_theory_optimal_with_respect_to_some_information-processing_task?.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2003.10245v2_Dichotomy_between_Deterministic_and_Probabilistic_Models_in_Countably_Additive_Effectus_Theory.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2201.12723v3_A_Frustratingly_Simple_Approach_for_End-to-End_Image_Captioning.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2203.13055v2_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_with_Choreographic_Memory.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2209.10106v1_Extreme_Multi-Domain_Multi-Task_Learning_With_Unified_Text-to-Text_Transfer_Transformers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2210.10542v1_PoseGPT_Quantization-based_3D_Human_Motion_Generation_and_Forecasting.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2211.11586v1_Random-LTD_Random_and_Layerwise_Token_Dropping_Brings_Efficient_Training_for_Large-scale_Transformers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2212.10559v2_Why_Can_GPT_Learn_In-Context?_Language_Models_Secretly_Perform_Gradient_Descent_as_Meta-Optimizers.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2301.04408v1_GPT_as_Knowledge_Worker_A_Zero-Shot_Evaluation_of_AICPA_Capabilities.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1310.4125v3_Generalised_probabilistic_theories_and_conic_extensions_of_polytopes.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1511.01549v2_Extension_of_Overbecks_Attack_for_Gabidulin_Based_Cryptosystems.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2007.01528v1_On-The-Fly_Information_Retrieval_Augmentation_for_Language_Models.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/2302.07267v5_Correct_answers_from_the_psychology_of_artificial_intelligence.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1204.0376v2_Classification_of_Multipartite_Entanglement_via_Negativity_Fonts.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1204.3035v2_Target_Identification_Using_Dictionary_Matching_of_Generalized_Polarization_Tensors.pdf\"\u001b[0m\n",
      "\u001b[32m[Processing] Retrieving paper metadata\u001b[0m\n",
      "\u001b[32m[Downloading] Using aria2 with 5 connections\u001b[0m\n",
      "\u001b[32m[Done] Paper saved to \"/home/nex/Downloads/ArXiv_Papers/1412.8524v1_Non-locality_in_theories_without_the_no-restriction_hypothesis.pdf\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dl(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Search(query='fastai', id_list=[], max_results=99, sort_by=<SortCriterion.Relevance: 'relevance'>, sort_order=<SortOrder.Descending: 'descending'>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mRequesting 100 results at offset 0\u001b[0m\n",
      "\u001b[36mRequesting page of results\u001b[0m\n",
      "\u001b[36mGot first page; 4 of inf results available\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "g = results(\"fastai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Search' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfastai_papers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Search' object is not iterable"
     ]
    }
   ],
   "source": [
    "list(fastai_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://arxiv.org/abs/2002.04688v2',\n",
       " 'http://arxiv.org/abs/2107.12598v1',\n",
       " 'http://arxiv.org/abs/2207.01088v1',\n",
       " 'http://arxiv.org/abs/1708.07120v3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from PyPDF2 import PdfReader\n",
    "def pdf(path):\n",
    "    text = \"\"\n",
    "    reader = PdfReader(path)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "#print(pdf(Path('/home/nex/Downloads/ArXiv_Papers/2002.04688_fastai_A_Layered_API_for_Deep_Learning.pdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(len, papers_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def papers_vector():\n",
    "  return [pdf(entry) for entry in path.ls() if str(entry).endswith(\"pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article\n",
      "fastai: A Layered API for Deep Learning\n",
      "Jeremy Howard\n",
      "1,2,†and Sylvain Gugger\n",
      "1,†\n",
      "1fast.ai; j@fast.ai, s@fast.ai\n",
      "2University of San Francisco\n",
      "† These authors contributed equally to this work.\n",
      "Abstract: fastai is a deep learning library which provides practitioners with high-level components that\n",
      "can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides\n",
      "researchers with low-level components that can be mixed and matched to build new approaches. It aims\n",
      "to do both things without substantial compromises in ease of use, ﬂexibility, or performance. This is\n",
      "possible thanks to a carefully layered architecture, which expresses common underlying patterns of many\n",
      "deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can\n",
      "be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and\n",
      "the ﬂexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a\n",
      "semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended\n",
      "in pure Python; an optimizer which refactors out the common functionality of modern optimizers into\n",
      "two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel\n",
      "2-way callback system that can access any part of the data, model, or optimizer and change it at any\n",
      "point during training; a new data block API; and much more. We have used this library to successfully\n",
      "create a complete deep learning course, which we were able to write more quickly than using previous\n",
      "approaches, and the code was more clear. The library is already in wide use in research, industry, and\n",
      "teaching.\n",
      "Keywords: deep learning; data processing pipelines\n",
      "1. Introduction\n",
      "fastai is a modern deep learning library, available from GitHub as open source under the Apache 2\n",
      "license, which can be installed directly using the conda or pip package managers. It includes complete\n",
      "documentation and tutorials, and is the subject of the book Deep Learning for Coders with fastai and PyTorch:\n",
      "AI Applications Without a PhD [1].\n",
      "fastai is organized around two main design goals: to be approachable and rapidly productive, while\n",
      "also being deeply hackable and conﬁgurable. Other libraries have tended to force a choice between\n",
      "conciseness and speed of development, or ﬂexibility and expressivity, but not both. We wanted to get\n",
      "the clarity and development speed of Keras [ 2] and the customizability of PyTorch. This goal of getting\n",
      "the best of both worlds has motivated the design of a layered architecture. A high-level API powers\n",
      "ready-to-use functions to train models in various applications, offering customizable models with sensible\n",
      "defaults. It is built on top of a hierarchy of lower-level APIs which provide composable building blocks.\n",
      "This way, a user wanting to rewrite part of the high-level API or add particular behavior to suit their needs\n",
      "doesn’t have to learn how to use the lowest level.arXiv:2002.04688v2  [cs.LG]  16 Feb 20202 of 27\n",
      "Figure 1. The layered API from fastai\n",
      "The high-level of the API is most likely to be useful to beginners and to practitioners who are mainly\n",
      "in interested in applying pre-existing deep learning methods. It offers concise APIs over four main\n",
      "application areas: vision, text, tabular and time-series analysis, and collaborative ﬁltering. These APIs\n",
      "choose intelligent default values and behaviors based on all available information. For instance, fastai\n",
      "provides a single Learner class which brings together architecture, optimizer, and data, and automatically\n",
      "chooses an appropriate loss function where possible. Integrating these concerns into a single class enables\n",
      "fastai to curate appropriate default choices. To give another example, generally a training set should be\n",
      "shufﬂed, and a validation does not. So fastai provides a single DataLoaders class which automatically\n",
      "constructs validation and training data loaders with these details already handled. This helps practitioners\n",
      "ensure that they don’t make mistakes such as failing to include a validation set. In addition, because the\n",
      "training set and validation set are integrated into a single class, fastai is able, by default, always to display\n",
      "metrics during training using the validation set.\n",
      "This use of intelligent defaults–based on our own experience or best practices–extends to incorporating\n",
      "state-of-the-art research wherever possible. For instance, transfer learning is critically important for training\n",
      "models quickly, accurately, and cheaply, but the details matter a great deal. fastai automatically provides\n",
      "transfer learning optimised batch-normalization [ 3] training, layer freezing, and discriminative learning\n",
      "rates [ 4]. In general, the library’s use of integrated defaults means it requires fewer lines of code from the3 of 27\n",
      "user to re-specify information or merely to connect components. As a result, every line of user code tends\n",
      "to be more likely to be meaningful, and easier to read.\n",
      "The mid-level API provides the core deep learning and data-processing methods for each of\n",
      "these applications, and low-level APIs provide a library of optimized primitives and functional and\n",
      "object-oriented foundations, which allows the mid-level to be developed and customised. The library\n",
      "itself is built on top of PyTorch [ 5], NumPy [ 6], PIL [ 7], pandas [ 8], and various other libraries. In order\n",
      "to achieve its goal of hackability, the library does not aim to supplant or hide these lower levels or this\n",
      "foundation. Within a fastai model, one can interact directly with the underlying PyTorch primitives; and\n",
      "within a PyTorch model, one can incrementally adopt components from the fastai library as conveniences\n",
      "rather than as an integrated package.\n",
      "We believe fastai meets its design goals. A user can create and train a state-of-the-art vision model\n",
      "using transfer learning with four understandable lines of code. Perhaps more tellingly, we have been able\n",
      "to implement recent deep learning research papers with just a couple of hours work, whilst matching the\n",
      "performance shown in the papers. We have also used the library for our winning entry in the DawnBench\n",
      "competition [9], training a ResNet-50 on ImageNet to accuracy in 18 minutes.\n",
      "The following sections describe the main functionality of the various API levels in more detail and\n",
      "review prior related work. We chose to include a lot of code to illustrate the concepts we are presenting.\n",
      "While that code made change slightly as the library or its dependencies evolve (it is running against fastai\n",
      "v2.0.0), the ideas behind stay the same. The next section reviews the high-level APIs \"out-of-the-box\"\n",
      "applications for some of the most used deep learning domains. The applications provided are vision, text,\n",
      "tabular, and collaborative ﬁltering.\n",
      "2. Applications\n",
      "2.1. Vision\n",
      "Here is an example of how to ﬁne-tune an ImageNet [ 10] model on the Oxford IIT Pets dataset [ 11]\n",
      "and achieve close to state-of-the-art accuracy within a couple of minutes of training on a single GPU:\n",
      "from fastai .vision . a l l import *\n",
      "path =untar_data (URLs .PETS )\n",
      "dls =ImageDataLoaders .from_name_re (path =path ,bs=64 ,\n",
      "fnames =get_image_files (path /\" images \" ) , pat = r ' /([^/]+) _\\d+. jpg$ ' ,\n",
      "item_tfms =RandomResizedCrop ( 4 5 0 , min_scale = 0 . 7 5 ) ,\n",
      "batch_tfms =[*aug_transforms (size =224 , max_warp = 0 . ) , Normalize .from_stats (*imagenet_stats ) ] )\n",
      "learn =cnn_learner (dls ,resnet34 ,metrics =error_rate )\n",
      "learn .fit_one_cycle ( 4 )\n",
      "This is not an excerpt; these are all of the lines of code necessary for this task. Each line of code does\n",
      "one important task, allowing the user to focus on what they need to do, rather than minor details. Let’s\n",
      "look at each line in turn:\n",
      "from fastai .vision . a l l import *\n",
      "This ﬁrst line imports all the necessary pieces from the library. fastai is designed to be usable in a\n",
      "read–eval–print loop (REPL) environment as well as in a complex software system. Even if using the\n",
      "\"import *\" syntax is not generally recommended, REPL programmers generally prefer the symbols they\n",
      "need to be directly available to them, which is why fastai supports the \"import \u0003\" style. The library is\n",
      "carefully designed to ensure that importing in this way only imports the symbols that are actually likely to\n",
      "be useful to the user and avoids cluttering the namespace or shadowing important symbols.4 of 27\n",
      "path =untar_data (URLs .PETS )\n",
      "The second line downloads a standard dataset from the fast.ai datasets collection (if not previously\n",
      "downloaded) to a conﬁgurable location ( ~/.fastai/data by default), extracts it (if not previously\n",
      "extracted), and returns a pathlib.Path object with the extracted location.\n",
      "dls =ImageDataLoaders .from_name_re ( . . . )\n",
      "This line sets up the DataLoaders object. This is an abstraction that represents a combination of\n",
      "training and validation data and will be described more in a later section. DataLoaders can be ﬂexibly\n",
      "deﬁned using the data block API (see 3.1), or, as here, can be built for speciﬁc predeﬁned applications\n",
      "using speciﬁc subclasses. In this case, the ImageDataLoaders subclass is created using a regular expression\n",
      "labeller. Many other labellers are provided, particularly focused on labelling based on different kinds of\n",
      "ﬁle and folder name patterns, which are very common across a wide range of datasets.\n",
      "One interesting feature of this API, which is also shared by lower-level fastai data APIs, is the\n",
      "separation of item level and batch level transforms. Item transforms are applied, in this case, to individual\n",
      "images on the CPU. Batch transforms , on the other hand, are applied to a mini-batch, on the GPU if available.\n",
      "While fastai supports data augmentation on the GPU, images need to be of the same size before being\n",
      "batched. aug_transforms() selects a set of data augmentations that work well across a variety of vision\n",
      "datasets and problems and can be fully customized by providing parameters to the function. This is a\n",
      "good example of a simple \"helper function\"; it is not strictly necessary, because the user can list all the\n",
      "augmentations that they require using the individual data augmentation classes. However, by providing a\n",
      "single function which curates best practices and makes the most common types of customization available\n",
      "through a single function, users have fewer pieces to learn in order to get good results.\n",
      "After deﬁning a DataLoaders object the user can easily look at the data with a single line of code:\n",
      "dls .show_batch ( )\n",
      "Figure 2. A DataLoaders object built with the fastai library knows how to show its elements in a meaningful\n",
      "way. Here the result on the Oxford IIT Pets image classiﬁcation dataset.\n",
      "learn =cnn_learner (dls ,resnet34 ,metrics =error_rate )\n",
      "This fourth line creates a Learner , which provides an abstraction combining an optimizer, a model,\n",
      "and the data to train it – this will be described in more detail in 4.1. Each application has a customized\n",
      "function that creates a Learner , which will automatically handle whatever details it can for the user. For\n",
      "instance, in this case it will download an ImageNet-pretrained model, if not already available, remove\n",
      "the classiﬁcation head of the model, replace it with a head appropriate for this particular dataset, and set\n",
      "appropriate defaults for the optimizer, weight decay, learning rate, and so forth (except where overridden\n",
      "by the user).5 of 27\n",
      "learn .fit_one_cycle ( 4 )\n",
      "The ﬁfth line ﬁts the model. In this case, it is using the 1cycle policy [ 12], which is a recent best\n",
      "practice for training and is not widely available in most deep learning libraries by default. It is annealing\n",
      "both the learning rates, and the momentums, printing metrics on the validation set, displaying results in\n",
      "an HTML table (if run in a Jupyter Notebook, or a console table otherwise), recording losses and metrics\n",
      "after every batch to allow plotting later, and so forth. A GPU will be used if one is available.\n",
      "After training a model the user can view the results in various ways, including analysing the errors\n",
      "with show_results() :\n",
      "learn .show_results ( )\n",
      "Figure 3. A Learner knows from the data and the model type how to represent the results. It can even\n",
      "highlight model errors (here predicted class at bottom and actual at top).\n",
      "Here is another example of a vision application, this time for segmentation on the CamVid dataset [ 13]:\n",
      "from fastai .vision . a l l import *\n",
      "path =untar_data (URLs .CAMVID )\n",
      "dls =SegmentationDataLoaders .from_label_func (path =path ,bs=8 ,\n",
      "fnames =get_image_files (path /\" images \" ) ,\n",
      "label_func = lambda o:path / ' l a b e l s ' / f' { o . stem } _P { o . s u f f i x } ' ,\n",
      "codes =np.loadtxt (path / ' codes . t x t ' , dtype = s t r ) ,\n",
      "batch_tfms =[*aug_transforms (size =(360 ,480) ) , Normalize .from_stats (*imagenet_stats ) ] )\n",
      "learn =unet_learner (dls ,resnet34 ,metrics =acc_segment )\n",
      "learn .fit_one_cycle ( 8 , pct_start = 0 . 9 )\n",
      "The lines of code to create and train this model are almost identical to those for a classiﬁcation model,\n",
      "except for those necessary to tell fastai about the differences in the processing of the input data. The\n",
      "exact same line of code that was used for the image classiﬁcation example can also be used to display the\n",
      "segmentation data:\n",
      "Figure 4. In this case, fastai knows that the data is for a segmentation task, and therefore it color-codes and\n",
      "overlays, with transparency, the segmentation layer on top of the input images.\n",
      "Furthermore, the user can also view the results of the model, which again are visualized automatically\n",
      "in a way suitable for this task:6 of 27\n",
      "Figure 5. For a segmentation task, the ground-truth mask is laid at the right of the predicted mask.\n",
      "2.2. Text\n",
      "In modern natural language processing (NLP), perhaps the most important approach to building\n",
      "models is through ﬁne-tuning pre-trained language models. To train a language model in fastai requires\n",
      "very similar code to the previous examples (here on the IMDb dataset [14]):\n",
      "from fastai .text . a l l import *\n",
      "path =untar_data (URLs .IMDB_SAMPLE )\n",
      "df_tok ,count =tokenize_df (pd.read_csv (path / ' t e x t s . csv ' ) , [ ' t e x t ' ] )\n",
      "dls_lm =TextDataLoaders .from_df (df_tok ,path =path ,\n",
      "vocab =make_vocab (count ) ,text_col = ' t e x t ' , is_lm =True )\n",
      "learn =language_model_learner (dls_lm ,AWD_LSTM ,metrics =Perplexity ( ) ] )\n",
      "learn .fit_one_cycle ( 1 , 2 e\u00002,moms = ( 0 . 8 , 0 . 7 , 0 . 8 ) )\n",
      "Fine-tuning this model for classiﬁcation requires the same basic steps:\n",
      "dls_clas =TextDataLoaders .from_df (df_tok ,path =path\n",
      "vocab =make_vocab (count ) ,text_col = ' t e x t ' , label_col = ' l a b e l ' )\n",
      "learn =text_classifier_learner (dls_clas ,AWD_LSTM ,metrics =accuracy )\n",
      "learn .fit_one_cycle ( 1 , 2 e\u00002,moms = ( 0 . 8 , 0 . 7 , 0 . 8 ) )\n",
      "The same API is also used to view the DataLoaders :\n",
      "Figure 6. In text classiﬁcation, the batches are shown in a DataFrame with the tokenized texts.\n",
      "The biggest challenge with creating text applications is often the processing of the input data.\n",
      "fastai provides a ﬂexible processing pipeline with predeﬁned rules for best practices, such as handling\n",
      "capitalization by adding tokens. For instance, there is a compromise between lower-casing all text and\n",
      "losing information, versus keeping the original capitalisation and ending up with too many tokens in your\n",
      "vocabulary. fastai handles this by adding a special single token representing that the next symbol should be\n",
      "treated as uppercase or sentence case and then converts the text itself to lowercase. fastai uses a number of7 of 27\n",
      "these special tokens. Another example is that a sequence of more than three repeated characters is replaced\n",
      "with a special repetition token, along with a number of repetitions and then the repeated character. These\n",
      "rules largely replicate the approaches discussed in [ 4] and are not normally made available as defaults in\n",
      "most NLP modelling libraries.\n",
      "The tokenization is ﬂexible and can support many different organizers. The default used is Spacy. A\n",
      "SentencePiece tokenizer [ 15] is also provided by the library. Subword tokenization [ 16] [17], such as that\n",
      "provided by SentencePiece, has been used in many recent NLP breakthroughs [18] [19].\n",
      "Numericalization and vocabulary creation often requires many lines of code, and careful management\n",
      "here fails and caching. In fastai that is handled transparently and automatically. Input data can be provided\n",
      "in many different forms, including: a separate ﬁle on disk for each document, delimited ﬁles in various\n",
      "formats, and so forth. The API also allows for complete customisation. SentencePiece is particularly useful\n",
      "for handling multiple languages and was used in MultiFIT [ 20], along with fastai, for this purpose. This\n",
      "provided models and state-of-the-art results across many different languages using a single code base.\n",
      "fastai’s text models are based on AWD-LSTM [ 21]. The user community have provided external\n",
      "connectors to the popular HuggingFace Transformers library [ 22]. The training of the models proceeds in\n",
      "the same way as for the vision examples with defaults appropriate for these models automatically selected.\n",
      "We are not aware of other libraries that provide direct support for transfer learning best practices in NLP ,\n",
      "such as those shown in [ 4]. Because the tokenisation is built on top of a layered architecture, users can\n",
      "replace the base tokeniser with their own choices and will automatically get support for the underlying\n",
      "parallel process model provided by fastai. It will also automatically handle serialization of intermediate\n",
      "outputs so that they can be reused in future processing pipelines.\n",
      "The results of training the model can be visualised with the same API as used for image models,\n",
      "shown in a way appropriate for NLP:\n",
      "Figure 7. In text classiﬁcation, results are displayed in a DataFrame with the tokenized texts.\n",
      "2.3. Tabular\n",
      "Tabular models have not been very widely used in deep learning; Gradient boosting machines\n",
      "and similar methods are more commonly used in industry and research settings. However, there have\n",
      "been examples of competition winning approaches and academic state-of-the-art results using deep\n",
      "learning [ 23]. Deep learning models are particularly useful for datasets with high cardinality categorical\n",
      "variables because they provide embeddings that can be used even for non-deep learning models [ 24].\n",
      "One of the challenges is there has not been examples of libraries which directly support best practices for\n",
      "tabular modelling using deep learning.\n",
      "The pandas library [ 8] already provides excellent support for processing tabular data sets, and fastai\n",
      "does not attempt to replace it. Instead, it adds additional functionality to pandas DataFrames through\n",
      "various pre-processing functions, such as automatically adding features that are useful for modelling with\n",
      "date data. fastai also provides features for automatically creating appropriate DataLoaders with separated8 of 27\n",
      "validation and training sets, using a variety of mechanisms, such as randomly splitting rows, or selecting\n",
      "rows based on some column.\n",
      "The code to create and train a model suitable for this data should look familiar, there is just information\n",
      "speciﬁc to tabular data requires when building the DataLoaders object.\n",
      "from fastai2 .tabular . a l l import *\n",
      "path =untar_data (URLs .ADULT_SAMPLE )\n",
      "df=pd.read_csv (path / ' adult . csv ' )\n",
      "dls =TabularDataLoaders .from_df (df,path ,\n",
      "procs =[Categorify ,FillMissing ,Normalize ] ,\n",
      "cat_names =[ ' workclass ' , ' education ' , ' marital \u0000s t a t u s ' , ' occupation ' , ' r e l a t i o n s h i p ' , ' race ' ] ,\n",
      "cont_names =[ ' age ' , ' fnlwgt ' , ' education \u0000num ' ] ,\n",
      "y_names = ' s a l a r y ' , valid_idx = l i s t ( range ( 1 0 2 4 , 1 2 6 0 ) ) , bs=64)\n",
      "learn =tabular_learner (dls ,layers = [ 2 0 0 , 1 0 0 ] , metrics =accuracy )\n",
      "learn .fit_one_cycle ( 3 )\n",
      "As for every other application, dls.show_batch andlearn.show_results will display a DataFrame\n",
      "with some samples.\n",
      "fastai also integrates with NVIDIA’s cuDF library, providing end-to-end GPU optimized data\n",
      "processing and model training. fastai is the ﬁrst deep learning framework to integrate with cuDF in\n",
      "this way.\n",
      "2.4. Collaborative ﬁltering\n",
      "Collaborative ﬁltering is normally modelled using a probabilistic matrix factorisation approach [ 25].\n",
      "In practice however, a dataset generally has much more than just (for example) a user ID and a product ID,\n",
      "but instead has many characteristics of the user, product, time period, and so forth. It is quite standard\n",
      "to use those to train a model, therefore, fastai attempts to close the gap between collaborative ﬁltering\n",
      "and tabular modelling. A collaborative ﬁltering model in fastai can be simply seen as a tabular model\n",
      "with high cardinality categorical variables. A classic matrix factorisation model is also provided. Both\n",
      "are trained using the same steps that we’ve seen in the other applications, as in this example using the\n",
      "popular Movielens dataset [26]:\n",
      "from fastai2 .collab import *\n",
      "ratings =pd.read_csv (untar_data (URLs .ML_SAMPLE ) / ' r a t i n g s . csv ' )\n",
      "dls =CollabDataLoaders .from_df (ratings ,bs=64 , seed =42)\n",
      "learn =collab_learner (dls ,n_factors =50 , y_range =[0 , 5 . 5 ] )\n",
      "learn .fit_one_cycle ( 3 )\n",
      "2.5. Deployment\n",
      "fastai is mostly focused on model training, but once this is done you can easily export the PyTorch\n",
      "model to serve it in production. The command Learner.export will serialize the model as well as the\n",
      "input pipeline (just the transforms, not the training data) to be able to apply the same to new data.\n",
      "The library provides Learner.predict andLearner.get_preds to evaluate the model on an item or\n",
      "a new inference DataLoader. Such a DataLoader can easily be built from a set of items with the command\n",
      "test_dl .9 of 27\n",
      "3. High-level API design considerations\n",
      "3.1. High-level API foundations\n",
      "The high-level API is that which is used by people using these applications. All the fastai applications\n",
      "share some basic components. One such component is the visualisation API, which uses a small number\n",
      "of methods, the main ones being show_batch (for showing input data) and show_results (for showing\n",
      "model results). Different types of model and datasets are able to use this consistent API because of fastai’s\n",
      "type dispatch system, a lower-level component which will be discussed in 5.3. The transfer learning\n",
      "capability shared across the applications relies on PyTorch’s parameter groups, and fastai’s mid-level API\n",
      "then leverages these groups, such as the generic optimizer (see 4.3).\n",
      "In all those applications, the Learner obtained gets the same functionality for the model training. The\n",
      "recommended way of training models using a variant of the 1cycle policy [ 12] which uses a warm-up and\n",
      "annealing for the learning rate while doing the opposite with the momentum parameter:\n",
      "Figure 8. The hyper-parameters schedule in the 1cycle policy.\n",
      "The learning rate is the most important hyper-parameter to tune (and very often the only one since\n",
      "the library sets proper defaults). Other libraries often provide help for grid search or AutoML to guess\n",
      "the best value, but the fastai library implements the learning rate ﬁnder [ 27] which much more quickly\n",
      "provides the best value for this parameter after a mock training. The command learn.lr_find() will\n",
      "return a graph like this:\n",
      "Figure 9. The learning rate ﬁnder does a mock training with an exponentially growing learning rate over\n",
      "100 iterations. A good value is then the minimum value on the graph divided by 10.\n",
      "Another important high-level API component, which is shared across all of the applications, is the\n",
      "data block API . The data block API is an expressive API for data loading. It is the ﬁrst attempt we are aware10 of 27\n",
      "of to systematically deﬁne all of the steps necessary to prepare data for a deep learning model, and give\n",
      "users a mix and match recipe book for combining these pieces (which we refer to as data blocks ). The steps\n",
      "that are deﬁned by the data block API are:\n",
      "• Getting the source items,\n",
      "• Splitting the items into the training set and one or more validation sets,\n",
      "• Labelling the items,\n",
      "• Processing the items (such as normalization), and\n",
      "• Optionally collating the items into batches.\n",
      "Here is an example of how to use the data block API to get the MNIST dataset [ 28] ready for modelling:\n",
      "mnist =DataBlock (\n",
      "blocks =(ImageBlock (cls=PILImageBW ) ,CategoryBlock ) ,\n",
      "get_items =get_image_files ,\n",
      "splitter =GrandparentSplitter ( ) ,\n",
      "get_y =parent_label )\n",
      "dls =mnist .databunch (untar_data (URLs .MNIST_TINY ) ,batch_tfms =Normalize )\n",
      "In fastai v1 and earlier we used a ﬂuent instead of a functional API for this (meaning the statements to\n",
      "execute those steps were chained one after the other). We discovered that this was a mistake; while ﬂuent\n",
      "APIs are ﬂexible in the order in which the user can deﬁne the steps, that order is very important in practice.\n",
      "With this functional DataBlock you don’t have to remember if you need to split before or after labelling\n",
      "your data, for instance. Also, ﬂuent APIs, at least in Python, tend not to work well with auto completion\n",
      "technologies. The data processing can be deﬁned using Transforms (see 5.2). Here is an example of using\n",
      "the data blocks API to complete the same segmentation seen earlier:\n",
      "path =untar_data (URLs .CAMVID_TINY )\n",
      "camvid =DataBlock (blocks =(ImageBlock ,ImageBlock (cls=PILMask ) ) ,\n",
      "get_items =get_image_files ,\n",
      "splitter =RandomSplitter ( ) ,\n",
      "get_y =lambda o:path / ' l a b e l s ' / f' { o . stem } _P { o . s u f f i x } ' )\n",
      "dls =camvid .databunch (path /\" images \" ,\n",
      "batch_tfms =[*aug_transforms ( ) , Normalize .from_stats (*imagenet_stats ) ] )\n",
      "Object detection can also be completed using the same functionality (here using the COCO\n",
      "dataset [29]):\n",
      "coco_source =untar_data (URLs .COCO_TINY )\n",
      "images ,lbl_bbox =get_annotations (coco_source / ' t r a i n . json ' )\n",
      "lbl = d i c t ( zip ( images ,lbl_bbox ) )\n",
      "coco =DataBlock (blocks =(ImageBlock ,BBoxBlock ,BBoxLblBlock ) ,\n",
      "get_items =get_image_files ,\n",
      "splitter =RandomSplitter ( ) ,\n",
      "getters =[noop , lambda o:lbl [o.name ] [ 0 ] , lambda o:lbl [o.name ] [ 1 ] ] ,\n",
      "n_inp =1)\n",
      "dls =coco .databunch (coco_source ,item_tfms =Resize ( 1 2 8 ) ,\n",
      "batch_tfms =[*aug_transforms ( ) , Normalize .from_stats (*imagenet_stats ) ] )\n",
      "In this case, the targets are a tuple of two things: a list of bounding boxes and a list of labels. This\n",
      "is why there are three blocks, a list of getters and an extra argument to specify how many of the blocks\n",
      "should be considered the input (the rest forming the target).\n",
      "The data for language modeling seen earlier can also be built using the data blocks API:11 of 27\n",
      "df=pd.read_csv (untar_data (URLs .IMDB_SAMPLE ) / ' t e x t s . csv ' )\n",
      "df_tok ,count =tokenize_df (df, ' t e x t ' )\n",
      "imdb_lm =DataBlock (blocks =TextBlock (make_vocab (count ) ,is_lm =True ) ,\n",
      "get_x =attrgetter ( ' t e x t ' ) ,\n",
      "splitter =RandomSplitter ( ) )\n",
      "dls =imdb_lm .databunch (df_tok ,bs=64 , seq_len =72)\n",
      "We have heard from users that they ﬁnd the data blocks API provides a good balance of conciseness\n",
      "and expressivity. Many libraries have provided various approaches to data processing. In the data science\n",
      "domain the scikit-learn [ 30]pipeline approach is widely used. This API provides a very high level of\n",
      "expressivity, but is not opinionated enough to ensure that a user completes all of the steps necessary to get\n",
      "their data ready for modelling. As another example, TensorFlow [ 31] provides the tf.data library, which\n",
      "does not as precisely map the steps necessary for users to complete their task to the functionality provided\n",
      "by the API. The Torchvision [ 32] library is a good example of an API which is highly specialised to a\n",
      "small subset of data processing tasks for a speciﬁc subdomain. fastai tries to capture the beneﬁts of both\n",
      "extremes of the spectrum, without compromises; the data blocks API is how most users transform their\n",
      "data for use with the library.\n",
      "3.2. Incrementally adapting PyTorch code\n",
      "Users often need to use existing pure PyTorch code (i.e. code that doesn’t use fastai), such as their\n",
      "existing code-bases developed without fastai, or using third party code written in pure PyTorch. fastai\n",
      "supports incrementally adding fastai features to this code, without requiring extensive rewrites.\n",
      "For instance, at the time of writing, the ofﬁcial PyTorch repository includes a MNIST training example1.\n",
      "In order to train this example using fastai’s Learner only two steps are required. First, the 30 lines in the\n",
      "example covering the test() andtrain() functions can be removed. Then, the 4 lines of the training loop\n",
      "is replaced with this code:\n",
      "data =DataLoaders (train_loader ,test_loader ) .cuda ( )\n",
      "learn =Learner (data ,Net ( ) , loss_func =F.nll_loss ,opt_func =Adam ,metrics =accuracy )\n",
      "learn .fit_one_cycle (epochs ,lr)\n",
      "With no other changes, the user now has the beneﬁt of all fastai’s callbacks, progress reporting,\n",
      "integrated schedulers such as 1cycle training, and so forth.\n",
      "3.3. Consistency across domains\n",
      "As the application examples have shown, the fastai library allows training a variety of kinds of\n",
      "application models, with a variety of kinds of datasets, using a very consistent API. The consistency\n",
      "covers not just the initial training, but also visualising and exploring the input data and model outputs.\n",
      "Such consistency helps students, both through having less to learn, and through showing the unifying\n",
      "concepts across different types of model. It also helps practitioners and researchers focus on their model\n",
      "development rather than learning incidental differences between APIs across domains. It is of particular\n",
      "beneﬁt when, for instance, an NLP expert tries to bring their expertise across to a computer vision\n",
      "application.\n",
      "There are many libraries that provide high-level APIs to speciﬁc applications, such as Facebook’s\n",
      "Torchvision [ 32], Detectron [ 33], and Fairseq [ 34]. However, each library has a different API, input\n",
      "1https://github.com/pytorch/examples/blob/master/mnist/main.py12 of 27\n",
      "representation, and requires different assumptions about training details, all of which a user must learn\n",
      "from scratch each time. This means that there are many deep learning practitioners and researchers who\n",
      "become specialists in speciﬁc subﬁelds, partially based on their understanding of the toiling of those\n",
      "subﬁelds. By providing a consistent API fastai users are able to quickly move between different ﬁelds and\n",
      "reuse their expertise.\n",
      "Customizing the behaviour of predeﬁned applications can be challenging, which means that\n",
      "researchers often end up \"reinventing the wheel\", or, constraining themselves to the speciﬁc parts which\n",
      "there tooling allows them to customize. Because fastai provides a layered architecture, users of the\n",
      "software can customize every part, as they need. The layered architecture is also an important foundation\n",
      "in allowing PyTorch users to incrementally add fastai functionality to existing code bases. Furthermore,\n",
      "fastai’s layers are reused across all applications, so an investment in learning them can be leveraged across\n",
      "many different projects.\n",
      "The approach of creating layered APIs has a long history in software engineering. Software\n",
      "engineering best practices involve building up decoupled components which can be tied together in\n",
      "ﬂexible ways, and then creating increasingly less abstract and more customized layers on top of each part.\n",
      "The layered API design is also important for researchers and practitioners aiming to create best in\n",
      "class results. As the ﬁeld of deep learning matures, there are more and more architectures, optimizers, data\n",
      "processing pipelines, and other approaches that can be selected from. Trying to bring multiple approaches\n",
      "together into a single project can be extremely challenging, when each one is using a different, incompatible\n",
      "API, and has different expectations about how a model is trained. For instance, in the original mixup\n",
      "article [ 35], the code provided by the researchers only works on one speciﬁc dataset, with one speciﬁc set\n",
      "of metrics, and with one speciﬁc optimizer. Attempting to combine the researchers’ mixup code with other\n",
      "training best practices, such as mixed precision training [ 36], requires rewriting it largely from scratch. The\n",
      "next section will look at the mid-level API pieces that fastai provides, which can be mixed and matched\n",
      "together to allow custom approaches to be quickly and reliably created.\n",
      "4. Mid-level APIs\n",
      "Many libraries, including fastai version 1 or earlier, provide a high-level API to users, and a low-level\n",
      "API used internally for that functionality, but nothing in between. This has two problems: the ﬁrst is that\n",
      "it becomes harder and harder to create additional high-level functionality, as the system becomes more\n",
      "sophisticated, because the low-level API becomes increasingly complicated and cluttered. The second\n",
      "problem is that for users of the system who want to customize and adapt it, they often have to rewrite\n",
      "signiﬁcant parts of the high-level API, and understand the large surface area of the low-level API in order\n",
      "to do so. This tends to mean that only a small dedicated community of specialists can really customize the\n",
      "software.\n",
      "These issues are common across nearly all software development, and many software engineers have\n",
      "worked hard to ﬁnd ways to deal with this complexity and develop layered architectures. The issue in the\n",
      "deep learning community, however, is that these practices have not seemed to be widely understood or\n",
      "adopted. There are, however, exceptions; most relevant to this paper, the PyTorch library [ 5] has a carefully\n",
      "layered design and is highly customizable.\n",
      "Much of the innovation in fastai is in its new mid-level APIs. This section will look at the following\n",
      "mid-level APIs: data, callbacks, optimizer, model layers, and metrics. These APIs are what the four fastai\n",
      "applications are built with and are also fully documented and available to users so that they can build\n",
      "their own applications or customize the existing ones.13 of 27\n",
      "4.1. Learner\n",
      "As already noted, a library can provide more appropriate defaults and user-friendly behaviour by\n",
      "ensuring that classes have all the information they need to make appropriate choices. One example of\n",
      "this is the DataLoaders class, which brings together all the information necessary for creating the data\n",
      "required for modelling. fastai also provides the Learner class, which brings together all the information\n",
      "necessary for training a model based on the data. The information which Learner requires, and is stored as\n",
      "state within a learner object, is: a PyTorch model, and optimizer, a loss function, and a DataLoaders object.\n",
      "Passing in the optimizer and loss function is optional, and in many situations fastai can automatically\n",
      "select appropriate defaults.\n",
      "Learner is also responsible (along with Optimizer ) for handling fastai’s transfer learning functionality.\n",
      "When creating a Learner the user can pass a splitter . This is a function that describes how to split the\n",
      "layers of a model into PyTorch parameter groups, which can then be frozen, trained with different learning\n",
      "rates, or more generally handled differently by an optimizer.\n",
      "One area that we have found particularly sensitive in transfer learning is the handling of\n",
      "batch-normalization layers [ 3]. We tried a wide variety of approaches to training and updating the\n",
      "moving average statistics of those layers, and different conﬁgurations could often change the error rate by\n",
      "as much as 300%. There was only one approach that consistently worked well across all datasets that we\n",
      "tried, which is to never freeze batch-normalization layers, and never turn off the updating of their moving\n",
      "average statistics. Therefore, by default, Learner will bypass batch-normalization layers when a user asks\n",
      "to freeze some parameter groups. Users often report that this one minor tweak dramatically improves\n",
      "their model accuracy and is not something that is found in any other libraries that we are aware of.\n",
      "DataLoaders andLearner also work together to ensure that model weights and input data are all on\n",
      "the same device. This makes working with GPUs signiﬁcantly more straightforward and makes it easy to\n",
      "switch from CPU to GPU as needed.\n",
      "4.2. Two-way callbacks\n",
      "In fastai version 0.7, we repeatedly modiﬁed the training loop in Learner to support many different\n",
      "tweaks and customizations. Over time, however, this became unwieldy. We noticed that there was a core\n",
      "subset of functionality that appeared in every one of these tweaks, and that all the other changes that were\n",
      "required could be refactored into a speciﬁc set of customization points. In other words, a wide variety of\n",
      "training methods can be represented using a single, universal training system. Once we extracted those\n",
      "common pieces, we were left with the basic fastai training loop, and the customisation points that we call\n",
      "two-way callbacks .\n",
      "The Learner class’s novel 2-way callback system allows gradients, data, losses, control ﬂow, and\n",
      "anything else to be read and changed at any point during training. There is a rich history of using callbacks\n",
      "to allow for customisation of numeric software, and today nearly all modern deep learning libraries\n",
      "provide this functionality. However, fastai’s callback system is the ﬁrst that we are aware of that supports\n",
      "the design principles necessary for complete two-way callbacks:\n",
      "•A callback should be available at every single point that code can be run during training, so that a\n",
      "user can customise every single detail of the training method ;\n",
      "•Every callback should be able to access every piece of information available at that stage in the\n",
      "training loop, including hyper-parameters, losses, gradients, input and target data, and so forth ;\n",
      "This is the way callbacks are usually designed, but in addition, there is a key design principle:14 of 27\n",
      "•Every callback should be able to modify all these pieces of information, at any time before they are\n",
      "used, and be able to skip a batch, epoch, training or validation section, or cancel the whole training\n",
      "loop.\n",
      "This is why we call these 2-way callbacks, as the information not only ﬂows from the training loop to\n",
      "the callbacks, but on the other way as well. For instance, here is the code for training a single batch bin\n",
      "fastai:\n",
      "t r y :\n",
      "self ._split (b) ; self .cb( ' begin_batch ' )\n",
      "self .pred =self .model (*self .x) ; self .cb( ' a f t e r _ p r e d ' )\n",
      "i f len ( self .y) == 0 : return\n",
      "self .loss =self .loss_func (self .pred ,*self .y) ;self .cb( ' a f t e r _ l o s s ' )\n",
      "i f not self .training : return\n",
      "self .loss .backward ( ) ; self .cb( ' a f t e r _ b a c k ' )\n",
      "self .opt .step ( ) ; self .cb( ' a f t e r _ s t e p ' )\n",
      "self .opt .zero_grad ( )\n",
      "except CancelBatchException : self .cb( ' a f t e r _ c a n c e l ' )\n",
      "f i n a l l y : self .cb( ' a f t e r _ b a t c h ' )\n",
      "This example clearly shows how every step of the process is associated with a callback (the calls to\n",
      "self.cb() and shows how exceptions are used as a ﬂexible control ﬂow mechanism for them.\n",
      "In fastai v0.7, we did not follow these three design principles. As a result, we had to frequently change\n",
      "the training loop to support additional functionality, and new research papers. On the other hand, with\n",
      "this new callback system we have not had to change the training loop at all, and have used callbacks to\n",
      "implement mixup augmentation, generative adversarial networks, optimized mixed precision training,\n",
      "PyTorch hooks, the learning rate ﬁnder, and many more. Most importantly, we have not yet come across\n",
      "any cases where mixing and matching these callbacks has caused any problems. Therefore, users can\n",
      "use all the training features that they want, and can easily do ablation studies, adding, removing, and\n",
      "modifying techniques as needed.\n",
      "4.2.1. Case study: generative adversarial network training using callbacks\n",
      "A good example of a fastai callback is GANTrainer , which implements training of generative\n",
      "adversarial networks [37]. To do so, it must complete the following tasks:\n",
      "• Freeze the generator and train the critic for one (or more) step by:\n",
      "–getting one batch of \"real\" images ;\n",
      "–generating one batch of \"fake\" images;\n",
      "–have the critic evaluate each batch and compute a loss function from that, which rewards\n",
      "positively the detection of real images and penalizes the fake ones;\n",
      "–update the weights of the critic with the gradients of this loss.\n",
      "• Freeze the critic and train the generator for one (or more) step by:\n",
      "–generating one batch of \"fake\" images;\n",
      "–evaluate the critic on it;\n",
      "–return a loss that rewards positively the critic thinking those are real images;\n",
      "–update the weights of the generator with the gradients of this loss.\n",
      "To do so, it relies on a GANModule that contains the generator and the critic, then delegates the input\n",
      "to the proper model depending on the value of a ﬂag gen_mode and on a GANLoss that also has a generator\n",
      "or critic behavior and handles the evaluation mentioned earlier. Then, it deﬁnes the following callback\n",
      "methods:15 of 27\n",
      "•begin_fit : Initialises the generator, critic, loss functions, and internal storage\n",
      "•begin_epoch : Sets the critic or generator to training mode\n",
      "•begin_validate : Switches to generator mode for showing results\n",
      "•begin_batch : Sets the appropriate target depending on whether it is in generator or critic mode\n",
      "•after_batch : Records losses to the generator or critic log\n",
      "•after_epoch : Optionally shows a sample image\n",
      "This callback is then customized with another callback, which deﬁnes at what point to switch\n",
      "from critic to generator and vice versa. fastai includes several possibilities for this purpose, such as\n",
      "anAdaptiveGANSwitcher , which automatically switches between generator and critic training based on\n",
      "reaching certain thresholds in their respective losses. This approach to training can allow models to be\n",
      "trained signiﬁcantly faster and more easily than with standard ﬁxed schedule approaches.\n",
      "4.3. Generic optimizer\n",
      "fastai provides a new generic optimizer foundation that allows recent optimization techniques to\n",
      "be implemented in a handful of lines of code, by refactoring out the common functionality of modern\n",
      "optimizers into two basic pieces:\n",
      "•stats , which track and aggregate statistics such as gradient moving averages ;\n",
      "•steppers , which combine stats and hyper-parameters to update the weights using some function.\n",
      "This has allowed us to implement every optimizer that we have attempted in fastai, without needing\n",
      "to extend or change this foundation. This has been very beneﬁcial, both for research and development.\n",
      "As an example of a development improvement, here are the entire changes needed to make to support\n",
      "decoupled weight decay (also known as AdamW [38]):\n",
      "steppers = [weight_decay ] i f decouple_wd e l s e [ l2_reg ]\n",
      "On the other hand, the implementation in the PyTorch library required creating an entirely new class,\n",
      "with over 50 lines of code. The beneﬁt for research comes about because it it easy to rapidly implement new\n",
      "papers as they come out, recognise similarities and differences across techniques, and try out variants and\n",
      "combinations of these underlying differences, many of which have not yet been published. The resulting\n",
      "code tends to look a lot like the maths shown in the paper. For instance, here is the code in fastai, and the\n",
      "algorithm from the paper, for the LAMB optimizer [39]:\n",
      "Figure 10. The LAMB algorithm and implementation.\n",
      "The only difference between the code and the ﬁgure are:\n",
      "• the means that update mtand vtdon’t appear as this done in a separate function stat;16 of 27\n",
      "•the authors do not provide the full deﬁnition of the ffunction they use (it depends on undeﬁned\n",
      "parameters), the code below is based on the ofﬁcial TensorFlow implementation.\n",
      "In order to support modern optimizers such as LARS fastai allows the user to choose whether to\n",
      "aggregate stats at model, layer, or per activation level.\n",
      "4.4. Generalized metric API\n",
      "Nearly all machine learning and deep learning libraries provide some support for metrics . These are\n",
      "generally deﬁned as simple functions which take the mean, or in some cases a custom reduction function,\n",
      "across some measurement which is logged during training. However, some metrics cannot be correctly\n",
      "deﬁned using this framework. For instance, the dice coefﬁcient, which is widely used for measuring\n",
      "segmentation accuracy, cannot be directly expressed using a simple reduction.\n",
      "In order to provide a more ﬂexible foundation to support metrics like this fastai provides a Metric\n",
      "abstract class which deﬁnes three methods: reset ,accumulate , and value (which is a property). Reset\n",
      "is called at the start of training, accumulate is called after each batch, and then ﬁnally value is called to\n",
      "calculate the ﬁnal check. Whenever possible, we can thus avoid recording and storing all predictions in\n",
      "memory. For instance, here is the deﬁnition of the dice coefﬁcient:\n",
      "c l a s s Dice (Metric ) :\n",
      "def __init__ (self ,axis =1) : self .axis =axis\n",
      "def reset (self ) :self .inter ,self .union = 0 ,0\n",
      "def accumulate (self ,learn ) :\n",
      "pred ,targ =flatten_check (learn .pred .argmax (self .axis ) ,learn .y)\n",
      "self .inter += ( pred *targ ) . f l o a t ( ) . sum ( ) . item ( )\n",
      "self .union += ( pred +targ ) . f l o a t ( ) . sum ( ) . item ( )\n",
      "@property\n",
      "def value (self ) : return 2 . *self .inter /self .union i fself .union >0 e l s e None\n",
      "The Scikit-learn library [ 30] already provides a wide variety of useful metrics, so instead of reinventing\n",
      "them, fastai provides a simple wrapper function, skm_to_fastai , which allows them to be used in fastai,\n",
      "and can automatically add pre-processing steps such as sigmoid, argmax, and thresholding.\n",
      "4.5. fastai.data.external\n",
      "Many libraries have recently started integrating access to external datasets directly into their APIs.\n",
      "fastai builds on this trend, by curating and collecting a number of datasets (hosted by the AWS Public\n",
      "Dataset Program2) in a single place and making them available through the fastai.data.external\n",
      "module. fastai automatically downloads, extracts, and caches these datasets when they are ﬁrst used. This\n",
      "is similar to functionality provided by Torchvision, TensorFlow datasets, and similar libraries, with the\n",
      "addition of closer integration into the fastai ecosystem. For instance, fastai provides cut-down “sample”\n",
      "versions of many of its datasets, which are small enough that they can be downloaded and used directly\n",
      "in documentation, continuous integration testing, and so forth. These datasets are also used in the\n",
      "documentation, along with examples showing users what they can expect when training models with his\n",
      "datasets. Because the documentation is written in interactive notebooks (as discussed in a later section)\n",
      "this also means that users can directly experiment with these datasets and models by simply running and\n",
      "modifying the documentation notebooks.\n",
      "2https://aws.amazon.com/opendata/public-datasets/17 of 27\n",
      "4.6. funcs_kwargs and DataLoader\n",
      "Once a user has their data available, they need to get it into a form that can be fed to a PyTorch\n",
      "model. The most common class used to feed models directly is the DataLoader class in PyTorch. This\n",
      "class provides fast and reliable multi-threaded data-processing execution, with several points allowing\n",
      "customisation. However, we have found that it is not ﬂexible enough to conveniently do some of the\n",
      "tasks that we have required, such as building a DataLoader for an NLP language model. Therefore, fastai\n",
      "includes a new DataLoader class on top of the internal classes that PyTorch uses. This combines the\n",
      "beneﬁts of the fast and reliable infrastructure provided by PyTorch with a more ﬂexible and expressive\n",
      "front-end for the user.\n",
      "DataLoader provides 15 extension points via customizable methods, which can be replaced by the\n",
      "user as required. These customizable methods represent the 15 stages of data loading that we have\n",
      "identiﬁed, and which ﬁt into three broad stages: sample creation, item creation, and batch creation. In\n",
      "contrast, in the standard PyTorch DataLoader class only a small subset of these stages is explicitly made\n",
      "available for customization by the user. Unless a user’s requirements are met by this subset, the user is\n",
      "forced to implement their own solution from scratch. The impact of this additional customizability can be\n",
      "quite signiﬁcant. For instance, the fastai language model DataLoader went from 90 lines of code to 30 lines\n",
      "of code after adopting this approach.\n",
      "What makes this ﬂexibility possible is a Python decorator that is called funcs_kwargs . This decorator\n",
      "creates a class in which any method can be replaced by passing a new function to the constructor, or by\n",
      "replacing it through subclassing. This allows users to replace any part of the logic in the DataLoader class.\n",
      "In order to maximise the power of this, nearly every part of the fastai DataLoader is a method with a\n",
      "single line of code. Therefore, virtually every design choice can be adjusted by users.\n",
      "fastai also provides a transformed DataLoader called TfmdDL , which subclasses DataLoader . In\n",
      "TfmdDL the callbacks and customization points execute Pipelines ofTransforms . Both mechanisms are\n",
      "described in 5.2; this section provides a brief overview here. A Transform is simply a Python function,\n",
      "which can also include its inverse function – that is, the function which “undoes” the transform. Transforms\n",
      "can be composed using the Pipeline class, which then allows the entire function composition to be\n",
      "inverted as well. We refer to these two directions, the forward and inverse directions of the functions, as\n",
      "theTransform s’encodes anddecodes methods.\n",
      "TfmdDL provides the foundations for the visualisation support discussed in the application section,\n",
      "having the basic template for showing a batch of data. In order to do this, it needs to decode any transforms\n",
      "in the pipeline, which it does automatically. For instance, an integer representing a level of a category will\n",
      "be converted back into the string that the integer represents.\n",
      "4.7. fastai.data.core\n",
      "When users who need to create a new kind of block for the data blocks API, or need a level of\n",
      "customization that even the data blocks API doesn’t support, they can use the mid-level components that\n",
      "the data block API is built on. These are a small number of simple classes which combine the transform\n",
      "pipelines functionality of fastai with Python’s collections interface.\n",
      "The most basic class is transformed list, or TfmdLists , which lazily applies a transform pipeline to\n",
      "a collection, whilst providing a standard Python collection interface. This is an important foundational\n",
      "functionality for deep learning, such as the ability to index into a collection of ﬁlenames, and on demand\n",
      "read an image ﬁle then apply any processing, such as data augmentation and normalization, necessary for\n",
      "a model. TfmdLists also provides subset functionality, which allows the user to deﬁne subsets of the data,\n",
      "such as those representing training and validation sets. Information about what subset an item belongs\n",
      "to is passed down to transforms, so that they can ensure that they do the appropriate processing – for18 of 27\n",
      "instance, data augmentation processing would be generally skipped for a validation set, unless doing test\n",
      "time augmentation.\n",
      "Another important data class at this layer of the API is Datasets , which applies multiple transform\n",
      "pipelines in parallel to a single collection. Like TfmdLists , it provides a standard Python collection\n",
      "interface. Indexing into a Datasets object returns a couple containing the result of each transform pipeline\n",
      "on the input item. This is the class used by the data blocks API to return, for instance, a tuple of an image\n",
      "tensor, and a label for that image, both derived from the same input ﬁlename.\n",
      "4.8. Layers and architectures\n",
      "PyTorch (like many other libraries) provides a basic “sequential” layer object, which can be combined\n",
      "in sequence to form a component of a network. This represents simple composition of functions, where\n",
      "each layer’s output is the next layer’s input. However, many components in modern network architectures\n",
      "cannot be represented in this way. For instance, ResNet blocks [ 40], and any other block which requires a\n",
      "skip connection, are not compatible with sequential layers. The normal workaround for this in PyTorch is\n",
      "to write a custom forward function, effectively relying on the full ﬂexibility of Python to escape the limits\n",
      "of composing these sequence layers.\n",
      "However, there is a signiﬁcant downside: the model is now no longer amenable to easy analysis and\n",
      "modiﬁcation, such as removing the ﬁnal few layers in order to do transfer learning. This also makes it\n",
      "harder to support automatic drawing graphs representing a model, printing a model summary, accurately\n",
      "reporting on model computation requirements by layer, and so forth.\n",
      "Therefore, fastai attempts to provide the basic foundations to allow modern neural network\n",
      "architectures to be built by stacking a small number of predeﬁned building blocks. The ﬁrst piece\n",
      "of this system is the SequentialEx layer. This layer has the same basic API as PyTorch’s nn.Sequential ,\n",
      "with one key difference: the original input value to the function is available to every layer in the block.\n",
      "Therefore, the user can, for instance, include a layer which adds the current value of the sequential block\n",
      "to the input value of the sequential block (such as is done in a ResNet).\n",
      "To take full advantage of this capability, fastai also provides a MergeLayer class. This allows the user\n",
      "to pass any function, which will in turn be provided with the layer block input value, and the current value\n",
      "of the sequential block. For instance, if you pass in a simple add function, then MergeLayer provides the\n",
      "functionality of an identity connection in a standard resnet block. Or, if the user passes in a concatenation\n",
      "function, then it provides the basic functionality of a concatenating connection in a Densenet block [ 41].\n",
      "In this way, fastai provides primitives which allow representing modern network architecture out of\n",
      "predeﬁned building blocks, without falling back to Python code in the forward function.\n",
      "fastai also provides a general-purpose class for combining these layers into a wide range of modern\n",
      "convolutional neural network architectures. These are largely based on the underlying foundations from\n",
      "ResNet [ 40], and therefore this class is called XResNet . By providing parameters to this class, the user can\n",
      "customise it to create architectures that include squeeze and excitation blocks [ 42], grouped convolutions\n",
      "such as in ResNext [ 43], depth-wise convolutions such as in the Xception architecture [ 44], widening\n",
      "factors such as in Wide ResNets [ 45], self-attention and symmetric self-attention functionality , custom\n",
      "activation functions, and more. By using this generic refactoring of these clusters of modern neural\n",
      "network architectures, we have been able to design and experiment with novel combinations very easily.\n",
      "It is also clearer to users exactly what is going on in their models, because the various speciﬁc architectures\n",
      "are clearly represented as changes to input parameters.\n",
      "One set of techniques that is extremely useful in practice are the tweaks to the ResNet architecture\n",
      "described in [ 46]. These approaches are used by default in XResNet . Another architecture tweak which has19 of 27\n",
      "worked well in many situations is the recently developed Mish activation function [ 47]. fastai includes an\n",
      "implementation of Mish which is optimised using PyTorch’s just-in-time compiler (JIT).\n",
      "A similar approach has been used to refactor the U-Net architecture [ 48]. Through looking at a range\n",
      "of competition winning and state-of-the-art papers in segmentation, we curated a set of approaches that\n",
      "work well together in practice. These are made available by default in fastai’s U-Net implementation,\n",
      "which also dynamically creates the U-Net cross connections for any given input size.\n",
      "5. Low-level APIs\n",
      "The layered approach of the fastai library has a speciﬁc meaning at the lower levels of it stack. Rather\n",
      "than treating Python [ 49] itself as the base layer of the computation, which the middle layer relies on, those\n",
      "layers rely on a set of basic abstractions provided by the lower layer. The middle layer is programmed in\n",
      "that set of abstractions. The low-level of the fastai stack provides a set of abstractions for:\n",
      "•Pipelines of transforms: Partially reversible composed functions mapped and dispatched over\n",
      "elements of tuples\n",
      "• Type-dispatch based on the needs of data processing pipelines\n",
      "•Attaching semantics to tensor objects, and ensuring that these semantics are maintained throughout\n",
      "aPipeline\n",
      "• GPU-optimized computer vision operations\n",
      "•Convenience functionality, such as a decorator to make patching existing objects easier, and a general\n",
      "collection class with a NumPy-like API.\n",
      "The rest of this section will explain how the transform pipeline system is built on top of the foundations\n",
      "provided by PyTorch, type dispatch, and semantic tensors, providing the ﬂexible infrastructure needed for\n",
      "the rest of fastai.\n",
      "5.1. PyTorch foundations\n",
      "The main foundation for fastai is the PyTorch [ 5] library. PyTorch provides a GPU optimised\n",
      "tensor class, a library of useful model layers, classes for optimizing models, and a ﬂexible programming\n",
      "model which integrates these elements. fastai uses building blocks from all parts of the PyTorch library,\n",
      "including directly patching its tensor class, entirely replacing its library of optimizers, providing simpliﬁed\n",
      "mechanisms for using its hooks, and so forth. In earlier prototypes of fastai we used TensorFlow [ 31] as\n",
      "our platform (and before that used [ 50]), but switched to PyTorch because we found that it had a fast core,\n",
      "a simple and well curated API, and rapidly growing popularity in the research community. At this point\n",
      "most papers at the top deep learning conferences are implemented using PyTorch.\n",
      "fastai builds on many other open source libraries. For CPU image processing fastai uses and extends\n",
      "the Python imaging library (PIL) [ 7], for reading and processing tabular data it uses pandas, for most of its\n",
      "metrics it uses Scikit-Learn [ 30], and for plotting it uses Matplotlib [ 51]. These are the most widely used\n",
      "libraries in the Python open source data science community and provide the features necessary for the\n",
      "fastai library.\n",
      "5.2. Transforms and Pipelines\n",
      "One key motivation is the need to often be able to undo some subset of transformations that are\n",
      "applied to create the data used to modelling. This strings that represent categories cannot be used in\n",
      "models directly and are turned into integers using some vocabulary. And pixel values for images are\n",
      "generally normalized. Neither of these can be directly visualized, and therefore at inference time we need\n",
      "to apply the inverse of these functions to get data that is understandable. Therefore, fastai introduces20 of 27\n",
      "aTransform class, which provides callable objects, along with a decode method. The decode method is\n",
      "designed to invert the function provided by a transform; it needs to be implemented manually by the user\n",
      "; it is similar to the inverse_transform you can provide in Scikit-Learn [ 30] pipelines and transformers.\n",
      "By providing both the encode and decode methods in a single place, the user ends up with a single object\n",
      "which they can compose into pipelines, serialize, and so forth.\n",
      "Another motivation for this part of the API is the insight that PyTorch data loaders provide tuples,\n",
      "and PyTorch models expect tuples as inputs. Sometimes these tuples should behave in a connected\n",
      "and dependent way, such as in a segmentation model, where data augmentation must be applied to\n",
      "both the independent and dependent variables in the same basic way. Sometimes, however, different\n",
      "implementations must be used for different types; for instance, when doing afﬁne transformations to\n",
      "a segmentation mask nearest-neighbor interpolation is needed, but for an image generally a smoother\n",
      "interpolation function would be used.\n",
      "In addition, sometimes transforms need to be able to opt out of processing altogether, depending on\n",
      "context. For instance, except when doing test time augmentation, data augmentation methods should\n",
      "not be applied to the validation set. Therefore, fastai automatically passes the current subset index\n",
      "to transforms, allowing them to modify their behaviour based on subset (for instance, training versus\n",
      "validation). This is largely hidden from the user, because base classes are provided which automatically\n",
      "do this context-dependent skipping. However, advanced users requiring complete customization can use\n",
      "this functionality directly.\n",
      "Transforms in deep learning pipelines often require state, which can be dependent on the input\n",
      "data. For example, normalization statistics could be based on a sample of data batches, a categorization\n",
      "transform could get its vocabulary directly from the dependent variable, or an NLP numericalization\n",
      "transform could get its vocabulary from the tokens used in the input corpus. Therefore, fastai transforms\n",
      "and pipelines support a setup method, which can be used to create this state when setting up a Pipeline .\n",
      "When pipelines are set up, all previous transforms in the pipeline are run ﬁrst, so that the transform being\n",
      "set up receives the same structure of data that it will when being called.\n",
      "This is closely connected to the implementation of TfmdList . Because a TfmdList lazily applies a\n",
      "pipeline to a collection, fastai can automatically call the Pipeline setup method as soon as it is connected\n",
      "to the collection in a TfmdList .\n",
      "5.3. Type dispatch\n",
      "The fastai type dispatch system is like the functools.singledispatch system provided in the Python\n",
      "standard library while supporting multiple dispatch over two parameters. Dispatch over two parameters\n",
      "is necessary for any situation where the user wants to be able to customize behavior based on both the\n",
      "input and target of a model. For instance, fastai uses this for the show_batch andshow_results methods.\n",
      "As shown in the application section, these methods automatically provide an appropriate visualisation of\n",
      "the input, target, and results of a model, which requires responding to the types of both parameters. In one\n",
      "example the input was an image, and the target was a segmentation mask, and the show results method\n",
      "automatically used a colour-coded overlay for the mask. On the other hand, for an image classiﬁcation\n",
      "problem, the input would be shown as an image, the prediction and target would be shown as text labels,\n",
      "and color-coded based on whether they were correct.\n",
      "It also provides a more expressive and yet concise syntax for registering additional dispatched\n",
      "functions or methods, taking advantage of Python’s recently introduced type annotations syntax. Here is\n",
      "an example of creating two different methods which dispatch based on parameter types:\n",
      "@typedispatch21 of 27\n",
      "def f_td_test (x:numbers .Integral ,y) : return x+1\n",
      "@typedispatch\n",
      "def f_td_test (x: int , y: f l o a t ) : return x+y\n",
      "Here f_td_test has a generic implementation for xof numeric types and all ys, then a specialized\n",
      "implementation when xis an intandyis afloat .\n",
      "5.4. Object-oriented semantic tensors\n",
      "By using fastai’s transform pipeline functionality, which depends heavily on types, the mid and\n",
      "high-level APIs can provide a lot of power, conciseness, and expressivity for users. However, this does not\n",
      "work well with the types provided by PyTorch, since the basic tensor type does not have any subclasses\n",
      "which can be used for type dispatch. Furthermore, subclassing PyTorch tensors is challenging, because the\n",
      "basic functionality for instantiating the subclasses is not provided and doing any kind of tensor operation\n",
      "will strip away the subclass information.\n",
      "Therefore, fastai provides a new tensor base class, which can be easily instantiated and subclass. fastai\n",
      "also patches PyTorch’s tensor class to attempt to maintain subclass information through operations\n",
      "wherever possible. Unfortunately, it is not possible to always perfectly maintain this information\n",
      "throughout every possible operation, and therefore all fastai Transform automatically maintain subclass\n",
      "types appropriately.\n",
      "fastai also provides the same functionality for Python imaging library classes, along with some basic\n",
      "type hierarchies for Python built-in collection types, NumPy arrays, and so forth.\n",
      "5.5. GPU-accelerated augmentation\n",
      "The fastai library provides most data augmentation in computer vision on the GPU at the batch level.\n",
      "Historically, the processing pipeline in computer vision has always been to open the images and apply\n",
      "data augmentation on the CPU, using a dedicated library such as PIL [ 7] or OpenCV [ 52], then batch the\n",
      "results before transferring them to the GPU and using them to train the model. On modern GPUs however,\n",
      "architectures like a standard ResNet-50 are often CPU-bound. Therefore fastai implements most common\n",
      "functions on the GPU, using PyTorch’s implementation of grid_sample (which does the interpolation\n",
      "from the coordinate map and the original image).\n",
      "Most data augmentations are random afﬁne transforms (rotation, zoom, translation, etc), functions on\n",
      "a coordinates map (perspective warping) or easy functions applied to the pixels (contrast or brightness\n",
      "changes), all of which can easily be parallelized and applied to a batch of images. In fastai, we combine all\n",
      "afﬁne and coordinate transforms in one step to only apply one interpolation, which results in a smoother\n",
      "result. Most other vision libraries do not do this and lose a lot of detail of the original image when applying\n",
      "several transformations in a row.\n",
      "Figure 11. A rotation and a zoom apply to an image with one interpolation only (right) or two interpolations\n",
      "(left). The latter results in more texture loss.22 of 27\n",
      "The type-dispatch system helps apply appropriate transforms to images, segmentation masks,\n",
      "key-points or bounding boxes (and users can add support for other types by writing their own functions).\n",
      "5.6. Convenience functionality\n",
      "fastai has a few more additions designed to make Python easier to use, including a NumPy-like API\n",
      "for lists called L, and some decorators to make delegation or patching easier.\n",
      "Delegation is used when one function will call another and send it a bunch of keyword arguments\n",
      "with defaults. To avoid repeating those, they are often grouped into **kwargs . The problem is that they\n",
      "then disappear from the signature of the function that delegates, and you can’t use the tools from modern\n",
      "IDEs to get tab-completion for those delegated arguments or see them in its signature. To solve this, fastai\n",
      "provides a decorator called @delegates that will analyze the signature of the delegated function to change\n",
      "the signature of the original function. For instance the initialization of Learner has 11 keyword-arguments,\n",
      "so any function that creates a Learner uses this decorator to avoid mentioning them all. As an example,\n",
      "the function tabular_learner is deﬁned like this:\n",
      "@delegates (Learner .__init__ )\n",
      "def tabular_learner (dls ,layers ,emb_szs =None ,config =None ,* *kwargs ) :\n",
      "but when you look at its signature, you will see the 11 additional arguments of Learner.__init__\n",
      "with their defaults.\n",
      "Monkey-patching is an important functionality of the Python language when you want to add\n",
      "functionality to existing objects. fastai makes it easier and more concise with a @patch decorator, using\n",
      "Python’s type-annotation system. For instance, here is how fastai adds the write() method to the\n",
      "pathlib.Path class:\n",
      "@patch\n",
      "def write (self :Path ,txt ,encoding = ' u t f 8 ' ) :\n",
      "self .parent .mkdir (parents =True ,exist_ok =True )\n",
      "with self . open ( 'w ' , encoding =encoding )as f :f.write (txt )\n",
      "Lastly, inspired by the NumPy [ 6] library, fastai provides a collection type, called L, that supports\n",
      "fancy indexing and has a lot of methods that allow users to write simple expressive code. For example, the\n",
      "code below takes a list of pairs, selects the second item of each pair, takes its absolute value, ﬁlters items\n",
      "greater than 4, and adds them up:\n",
      "d= d i c t ( a=1 ,b=\u00005,d=6 ,e=9) . items ( )\n",
      "L(d) .itemgot ( 1 ) . map( abs ) . f i l t e r ( gt( 4 ) ) . sum ( )\n",
      "Luses context-dependent functionality to simplify user code. For instance, the sorted method can\n",
      "take any of the following as a key: a callable (sorts based on the value of calling the key with the item), a\n",
      "string (used as an attribute name), or an int (used as an index).\n",
      "6. nbdev\n",
      "In order to assist in developing this library, we built a programming environment called nbdev, which\n",
      "allows users to create complete Python packages, including tests and a rich documentation system, all in\n",
      "Jupyter Notebooks [ 53]. nbdev is a system for exploratory programming . Exploratory programming is based\n",
      "on the observation that most developers spend most of their time as coders exploring and experimenting.\n",
      "Exploration is easiest developing on the prompt (or REPL), or using a notebook-oriented development23 of 27\n",
      "system like Jupyter Notebooks. But these systems are not as strong for the “programming” part, since\n",
      "they’re missing features provided by IDEs and editors like good documentation lookup, good syntax\n",
      "highlighting, integration with unit tests, and (most importantly) the ability to produce ﬁnal, distributable\n",
      "source code ﬁles.\n",
      "nbdev is built on top of Jupyter Notebook and adds the following critically important tools for\n",
      "software development:\n",
      "•Python modules are automatically created, following best practices such as automatically deﬁning\n",
      "__all__ with exported functions, classes, and variables\n",
      "•Navigate and edit code in a standard text editor or IDE, and export any changes automatically back\n",
      "into your notebooks\n",
      "•Automatically create searchable, hyperlinked documentation from your code (as seen in ﬁgure 12;\n",
      "any word surrounded in backticks will by hyperlinked to the appropriate documentation, a sidebar\n",
      "is created in the documentation site with links to each of module, and more\n",
      "• Pip installers (uploaded to pypi automatically)\n",
      "• Testing (deﬁned directly in notebooks, and run in parallel)\n",
      "• Continuous integration\n",
      "• Version control conﬂict handling\n",
      "We plan to provide more information about the features, beneﬁts, and history behind nbdev in a\n",
      "future paper.\n",
      "Figure 12. Example of fastai’s documentation, automatically generated using nbdev\n",
      "7. Related work\n",
      "There has been a long history of high-level APIs for deep learning in Python, and this history has\n",
      "been a signiﬁcant inﬂuence on the development of fastai. The ﬁrst example of a Python library for deep\n",
      "learning that we have found is Calysto/conx, which implemented back propagation in Python in 2001.\n",
      "Since that time there have been dozens of approaches to high-level APIs with perhaps the most signiﬁcant,\n",
      "in chronological order, being Lasagne [ 54] (begun in 2013), Fuel/Blocks (begun in 2014), and Keras [ 2]\n",
      "(begun in 2015). There have been other directions as well, such as the conﬁguration-based approach\n",
      "popularized by Caffe [ 55], and lower-level libraries such as Theano [ 50], TensorFlow [ 31] and PyTorch [ 5].\n",
      "APIs from general machine learning libraries have also been an important inﬂuence on fastai. SPSS\n",
      "and SAS provided many utilities for data processing and analysis since the early days of statistical\n",
      "computing. The development of the S language was a very signiﬁcant advance, which led directly to\n",
      "projects such as R [ 56], SPLUS, and xlisp-stat [ 57]. The direction taken by R for both data processing (largely24 of 27\n",
      "focused on the “Tidyverse” [ 58]) and model building (built on top of R’s rich “formula” system) shows\n",
      "how a very different set of design choices can result in a very different (and effective) user experience.\n",
      "Scikit-learn [ 30], Torchvision [ 32], and pandas [ 8] are examples of libraries which provide a function\n",
      "composition abstraction that (like fastai’s Pipeline ) are designed to help users process their data into the\n",
      "format they need (Scikit-Learn also being able to perform learning and predictions on that processed data).\n",
      "There are also projects such as MLxtend [ 59] that provide a variety of utilities building on the functionality\n",
      "of their underlying programming languages (Python, in the case of MLxtend).\n",
      "The most important inﬂuence on fastai is, of course, PyTorch [ 5]; fastai would not have been possible\n",
      "without it. The PyTorch API is extensible and ﬂexible, and the implementation is efﬁcient. fastai makes\n",
      "heavy use of torch.Tensor and torch.nn (including torch.nn.functional ). On the other hand, fastai\n",
      "does not make much use of PyTorch’s higher level APIs, such as nn.optim and annealing, instead\n",
      "independently creating overlapping functionality based on the design approaches and goals described\n",
      "above.\n",
      "8. Results and conclusion\n",
      "Early results from using fastai are very positive. We have used the fastai library to rewrite the entire\n",
      "fast.ai course “Practical Deep Learning for Coders”, which contains 14 hours of material, across seven\n",
      "modules, and covers all the applications described in this paper (and some more). We found that we were\n",
      "able to replicate or improve on all the results in previous versions of the material and were able to create\n",
      "the data pipelines and models needed much more quickly and easily than we could before. We have also\n",
      "heard from early adopters of pre-release versions of the library that they have been able to more quickly\n",
      "and easily write deep learning code and build models than with previous versions. fastai has already been\n",
      "selected as part of the ofﬁcial PyTorch Ecosystem3. According to the 2019 Kaggle ML & DS Survey4, 10%\n",
      "of data scientists in the Kaggle community are already using fastai. Many researchers are using fastai to\n",
      "support their work (e.g. [60] [61] [62] [63]).\n",
      "Based on our experience with fastai, we believe that using a layered API in deep learning has very\n",
      "signiﬁcant beneﬁts for researchers, practitioners, and students. Researchers can see links across different\n",
      "areas more easily, rapidly combine and restructure ideas, and run experiments on top of strong baselines.\n",
      "Practitioners can quickly build prototypes, and then build on and optimize those prototypes by leveraging\n",
      "fastai’s PyTorch foundations, without rewriting code. Students can experiment with models and try out\n",
      "variations, without being overwhelmed by boilerplate code when ﬁrst learning ideas.\n",
      "The basic ideas expressed in fastai are not limited to use in PyTorch, or even Python. There is already\n",
      "a partial port of fastai to Swift, called SwiftAI [ 64], and we hope to see similar projects for more languages\n",
      "and libraries in the future.\n",
      "Author Contributions: Both authors contributed equally to this work.\n",
      "Funding: This research received no external funding. Sylvain has been sponsored by AWS in 2018-2019 and by Google\n",
      "in 2019-2020.\n",
      "Acknowledgments: We would like to express our deep appreciation to Alexis Gallagher, who was instrumental\n",
      "throughout the paper-writing process, and who inspired the functional-style data blocks API. Many thanks also to the\n",
      "Facebook PyTorch team for all their support throughout fastai’s development, to the global fast.ai community who\n",
      "through forums.fast.ai have contributed many ideas and pull requests that have been invaluable to the development of\n",
      "fastai, to Chris Lattner and the Swift for TensorFlow team who helped develop the Swift courses at course.fast.ai and\n",
      "SwiftAI, to Andrew Shaw for contributing to early prototypes of showdoc in nbdev, to Stas Bekman for contributing\n",
      "3https://pytorch.org/ecosystem/\n",
      "4https://www.kaggle.com/c/kaggle-survey-201925 of 27\n",
      "to early prototypes of the git hooks in nbdev and to packaging and utilities, and to the developers of the Python\n",
      "programming language, which provides such a strong foundation for fastai’s features.\n",
      "Conﬂicts of Interest: The authors declare no conﬂict of interest.\n",
      "References\n",
      "1. Howard, J.; Gugger, S. Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD , 1st ed.;\n",
      "O’Reilly Media, Inc., 2020.\n",
      "2. Chollet, F.; others. Keras. https://keras.io, 2015.\n",
      "3. Ioffe, S.; Szegedy, C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate\n",
      "Shift. CoRR 2015 ,abs/1502.03167 , [1502.03167].\n",
      "4. Howard, J.; Ruder, S. Fine-tuned Language Models for Text Classiﬁcation. CoRR 2018 ,abs/1801.06146 ,\n",
      "[1801.06146].\n",
      "5. Paszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.; DeVito, Z.; Lin, Z.; Desmaison, A.; Antiga, L.; Lerer, A.\n",
      "Automatic Differentiation in PyTorch. NIPS Autodiff Workshop, 2017.\n",
      "6. Oliphant, T. NumPy: A guide to NumPy. USA: Trelgol Publishing, 2006–. [Online; accessed <today>].\n",
      "7. Clark, A.; Contributors. Python Imaging Library (Pillow fork). https://github.com/python-pillow/Pillow.\n",
      "8. McKinney, W. Data Structures for Statistical Computing in Python. Proceedings of the 9th Python in Science\n",
      "Conference; van der Walt, S.; Millman, J., Eds., 2010, pp. 51 – 56.\n",
      "9. Cody A. Coleman, Deepak Narayanan, D.K.T.Z.J.Z.L.N.P .B.K.O.C.R.; Zahari, M. DAWNBench: An End-to-End\n",
      "Deep Learning Benchmark and Competition. NIPS ML Systems Workshop, 2017 2017 .\n",
      "10. Deng, J.; Dong, W.; Socher, R.; Li, L.J.; Li, K.; Fei-Fei, L. ImageNet: A Large-Scale Hierarchical Image Database.\n",
      "CVPR09, 2009.\n",
      "11. Parkhi, O.M.; Vedaldi, A.; Zisserman, A.; Jawahar, C.V . Cats and Dogs. IEEE Conference on Computer Vision\n",
      "and Pattern Recognition, 2012.\n",
      "12. Smith, L.N. A disciplined approach to neural network hyper-parameters: Part 1 - learning rate, batch size,\n",
      "momentum, and weight decay. CoRR 2018 ,abs/1803.09820 , [1803.09820].\n",
      "13. Brostow, G.J.; Shotton, J.; Fauqueur, J.; Cipolla, R. Segmentation and Recognition Using Structure from Motion\n",
      "Point Clouds. ECCV (1), 2008, pp. 44–57.\n",
      "14. Maas, A.L.; Daly, R.E.; Pham, P .T.; Huang, D.; Ng, A.Y.; Potts, C. Learning Word Vectors for Sentiment Analysis.\n",
      "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language\n",
      "Technologies; Association for Computational Linguistics: Portland, Oregon, USA, 2011; pp. 142–150.\n",
      "15. Kudo, T.; Richardson, J. SentencePiece: A simple and language independent subword tokenizer and detokenizer\n",
      "for Neural Text Processing. CoRR 2018 ,abs/1808.06226 , [1808.06226].\n",
      "16. Wu, Y.; Schuster, M.; Chen, Z.; Le, Q.V .; Norouzi, M.; Macherey, W.; Krikun, M.; Cao, Y.; Gao, Q.; Macherey, K.;\n",
      "Klingner, J.; Shah, A.; Johnson, M.; Liu, X.; Kaiser, L.; Gouws, S.; Kato, Y.; Kudo, T.; Kazawa, H.; Stevens, K.;\n",
      "Kurian, G.; Patil, N.; Wang, W.; Young, C.; Smith, J.; Riesa, J.; Rudnick, A.; Vinyals, O.; Corrado, G.; Hughes,\n",
      "M.; Dean, J. Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine\n",
      "Translation. CoRR 2016 ,abs/1609.08144 , [1609.08144].\n",
      "17. Kudo, T. Subword Regularization: Improving Neural Network Translation Models with Multiple Subword\n",
      "Candidates. CoRR 2018 ,abs/1804.10959 , [1804.10959].\n",
      "18. Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever, I. Language Models are Unsupervised Multitask\n",
      "Learners 2019 .\n",
      "19. Devlin, J.; Chang, M.; Lee, K.; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for\n",
      "Language Understanding. CoRR 2018 ,abs/1810.04805 , [1810.04805].\n",
      "20. Eisenschlos, J.; Ruder, S.; Czapla, P .; Kadras, M.; Gugger, S.; Howard, J. MultiFiT: Efﬁcient Multi-lingual\n",
      "Language Model Fine-tuning. Proceedings of the 2019 Conference on Empirical Methods in Natural Language\n",
      "Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) 2019 .\n",
      "doi:10.18653/v1/d19-1572.26 of 27\n",
      "21. Merity, S.; Keskar, N.S.; Socher, R. Regularizing and Optimizing LSTM Language Models. CoRR 2017 ,\n",
      "abs/1708.02182 , [1708.02182].\n",
      "22. Wolf, T.; Debut, L.; Sanh, V .; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P .; Rault, T.; Louf, R.; Funtowicz, M.;\n",
      "Brew, J. HuggingFace’s Transformers: State-of-the-art Natural Language Processing. ArXiv 2019 ,abs/1910.03771 .\n",
      "23. de Brébisson, A.; Simon, É.; Auvolat, A.; Vincent, P .; Bengio, Y. Artiﬁcial Neural Networks Applied to Taxi\n",
      "Destination Prediction. CoRR 2015 ,abs/1508.00021 , [1508.00021].\n",
      "24. Guo, C.; Berkhahn, F. Entity Embeddings of Categorical Variables. CoRR 2016 ,abs/1604.06737 , [1604.06737].\n",
      "25. Mnih, A.; Salakhutdinov, R.R. Probabilistic matrix factorization. Advances in neural information processing\n",
      "systems, 2008, pp. 1257–1264.\n",
      "26. Harper, F.M.; Konstan, J.A. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst.\n",
      "2015 ,5, 19:1–19:19. doi:10.1145/2827872.\n",
      "27. Smith, L.N. No More Pesky Learning Rate Guessing Games. CoRR 2015 ,abs/1506.01186 , [1506.01186].\n",
      "28. LeCun, Y.; Cortes, C.; Burges, C. MNIST handwritten digit database. AT&T Labs [Online]. Available: http://yann.\n",
      "lecun. com/exdb/mnist 2010 ,2, 18.\n",
      "29. Lin, T.; Maire, M.; Belongie, S.J.; Bourdev, L.D.; Girshick, R.B.; Hays, J.; Perona, P .; Ramanan, D.; Dollár, P .;\n",
      "Zitnick, C.L. Microsoft COCO: Common Objects in Context. CoRR 2014 ,abs/1405.0312 , [1405.0312].\n",
      "30. Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V .; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P .;\n",
      "Weiss, R.; Dubourg, V .; Vanderplas, J.; Passos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; Duchesnay, E.\n",
      "Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 2011 ,12, 2825–2830.\n",
      "31. Abadi, M.; Agarwal, A.; Barham, P .; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G.S.; Davis, A.; Dean, J.; Devin,\n",
      "M.; Ghemawat, S.; Goodfellow, I.; Harp, A.; Irving, G.; Isard, M.; Jia, Y.; Jozefowicz, R.; Kaiser, L.; Kudlur,\n",
      "M.; Levenberg, J.; Mané, D.; Monga, R.; Moore, S.; Murray, D.; Olah, C.; Schuster, M.; Shlens, J.; Steiner, B.;\n",
      "Sutskever, I.; Talwar, K.; Tucker, P .; Vanhoucke, V .; Vasudevan, V .; Viégas, F.; Vinyals, O.; Warden, P .; Wattenberg,\n",
      "M.; Wicke, M.; Yu, Y.; Zheng, X. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, 2015.\n",
      "Software available from tensorﬂow.org.\n",
      "32. Massa, F.; Chintala, S. Torchvision. https://github.com/pytorch/vision/tree/master/torchvision.\n",
      "33. Girshick, R.; Radosavovic, I.; Gkioxari, G.; Dollár, P .; He, K. Detectron. https://github.com/facebookresearch/\n",
      "detectron, 2018.\n",
      "34. Ott, M.; Edunov, S.; Baevski, A.; Fan, A.; Gross, S.; Ng, N.; Grangier, D.; Auli, M. fairseq: A Fast, Extensible\n",
      "Toolkit for Sequence Modeling. Proceedings of NAACL-HLT 2019: Demonstrations, 2019.\n",
      "35. Zhang, H.; Cissé, M.; Dauphin, Y.N.; Lopez-Paz, D. mixup: Beyond Empirical Risk Minimization. CoRR 2017 ,\n",
      "abs/1710.09412 , [1710.09412].\n",
      "36. Micikevicius, P .; Narang, S.; Alben, J.; Diamos, G.; Elsen, E.; Garcia, D.; Ginsburg, B.; Houston, M.; Kuchaiev,\n",
      "O.; Venkatesh, G.; Wu, H. Mixed Precision Training, 2017, [arXiv:cs.AI/1710.03740].\n",
      "37. Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; Bengio, Y.\n",
      "Generative Adversarial Nets. In Advances in Neural Information Processing Systems 27 ; Ghahramani, Z.; Welling,\n",
      "M.; Cortes, C.; Lawrence, N.D.; Weinberger, K.Q., Eds.; Curran Associates, Inc., 2014; pp. 2672–2680.\n",
      "38. Loshchilov, I.; Hutter, F. Fixing Weight Decay Regularization in Adam. CoRR 2017 ,abs/1711.05101 , [1711.05101].\n",
      "39. You, Y.; Li, J.; Hseu, J.; Song, X.; Demmel, J.; Hsieh, C. Reducing BERT Pre-Training Time from 3 Days to 76\n",
      "Minutes. CoRR 2019 ,abs/1904.00962 , [1904.00962].\n",
      "40. He, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image Recognition. CoRR 2015 ,abs/1512.03385 ,\n",
      "[1512.03385].\n",
      "41. Huang, G.; Liu, Z.; Weinberger, K.Q. Densely Connected Convolutional Networks. CoRR 2016 ,abs/1608.06993 ,\n",
      "[1608.06993].\n",
      "42. Hu, J.; Shen, L.; Sun, G. Squeeze-and-Excitation Networks. CoRR 2017 ,abs/1709.01507 , [1709.01507].\n",
      "43. Xie, S.; Girshick, R.; Dollar, P .; Tu, Z.; He, K. Aggregated Residual Transformations for Deep Neural Networks.\n",
      "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017 . doi:10.1109/cvpr.2017.634.\n",
      "44. Chollet, F. Xception: Deep Learning with Depthwise Separable Convolutions. CoRR 2016 ,abs/1610.02357 ,\n",
      "[1610.02357].27 of 27\n",
      "45. Zagoruyko, S.; Komodakis, N. Wide Residual Networks. CoRR 2016 ,abs/1605.07146 , [1605.07146].\n",
      "46. He, T.; Zhang, Z.; Zhang, H.; Zhang, Z.; Xie, J.; Li, M. Bag of Tricks for Image Classiﬁcation with Convolutional\n",
      "Neural Networks. CoRR 2018 ,abs/1812.01187 , [1812.01187].\n",
      "47. Misra, D. Mish: A Self Regularized Non-Monotonic Neural Activation Function, 2019,\n",
      "[arXiv:cs.LG/1908.08681].\n",
      "48. Ronneberger, O.; Fischer, P .; Brox, T. U-Net: Convolutional Networks for Biomedical Image Segmentation.\n",
      "CoRR 2015 ,abs/1505.04597 , [1505.04597].\n",
      "49. Python Core Team. Python: A dynamic, open source programming language . Python Software Foundation, 2019.\n",
      "Python version 3.7.\n",
      "50. Theano Development Team. Theano: A Python framework for fast computation of mathematical expressions.\n",
      "arXiv e-prints 2016 ,abs/1605.02688 .\n",
      "51. Hunter, J.D. Matplotlib: A 2D graphics environment. Computing in science & engineering 2007 ,9, 90.\n",
      "52. Bradski, G. The OpenCV Library. Dr. Dobb’s Journal of Software Tools 2000 .\n",
      "53. Kluyver, T.; Ragan-Kelley, B.; Pérez, F.; Granger, B.; Bussonnier, M.; Frederic, J.; Kelley, K.; Hamrick, J.; Grout,\n",
      "J.; Corlay, S.; Ivanov, P .; Avila, D.; Abdalla, S.; Willing, C. Jupyter Notebooks – a publishing format for\n",
      "reproducible computational workﬂows. Positioning and Power in Academic Publishing: Players, Agents and\n",
      "Agendas; Loizides, F.; Schmidt, B., Eds. IOS Press, 2016, pp. 87 – 90.\n",
      "54. Dieleman, S.; Schlüter, J.; Raffel, C.; Olson, E.; Sønderby, S.K.; Nouri, D.; Maturana, D.; Thoma, M.; Battenberg,\n",
      "E.; Kelly, J.; Fauw, J.D.; Heilman, M.; de Almeida, D.M.; McFee, B.; Weideman, H.; Takács, G.; de Rivaz, P .; Crall,\n",
      "J.; Sanders, G.; Rasul, K.; Liu, C.; French, G.; Degrave, J. Lasagne: First release., 2015. doi:10.5281/zenodo.27878.\n",
      "55. Jia, Y.; Shelhamer, E.; Donahue, J.; Karayev, S.; Long, J.; Girshick, R.; Guadarrama, S.; Darrell, T. Caffe:\n",
      "Convolutional Architecture for Fast Feature Embedding. arXiv preprint arXiv:1408.5093 2014 .\n",
      "56. R Core Team. R: A Language and Environment for Statistical Computing . R Foundation for Statistical Computing,\n",
      "Vienna, Austria, 2017.\n",
      "57. Luke Tierney. XLISP-STAT: A Statistical Environment Based on the XLISP Language (Version 2.0). Technical\n",
      "Report 28, School of Statistics, University of Minnesota, 1989.\n",
      "58. Wickham, H.; Averick, M.; Bryan, J.; Chang, W.; McGowan, L.D.; François, R.; Grolemund, G.; Hayes, A.; Henry,\n",
      "L.; Hester, J.; Kuhn, M.; Pedersen, T.L.; Miller, E.; Bache, S.M.; Müller, K.; Ooms, J.; Robinson, D.; Seidel, D.P .;\n",
      "Spinu, V .; Takahashi, K.; Vaughan, D.; Wilke, C.; Woo, K.; Yutani, H. Welcome to the tidyverse. Journal of Open\n",
      "Source Software 2019 ,4, 1686. doi:10.21105/joss.01686.\n",
      "59. Raschka, S. MLxtend: Providing machine learning and data science utilities and extensions to Python’s\n",
      "scientiﬁc computing stack. The Journal of Open Source Software 2018 ,3. doi:10.21105/joss.00638.\n",
      "60. Revay, S.; Teschke, M. Multiclass Language Identiﬁcation using Deep Learning on Spectral Images of Audio\n",
      "Signals, 2019, [arXiv:1905.04348].\n",
      "61. Koné, I.; Boulmane, L. Hierarchical ResNeXt Models for Breast Cancer Histology Image Classiﬁcation. CoRR\n",
      "2018 ,abs/1810.09025 , [1810.09025].\n",
      "62. Elkins, A.; Freitas, F.F.; Sanz, V . Developing an App to interpret Chest X-rays to support the diagnosis of\n",
      "respiratory pathology with Artiﬁcial Intelligence, 2019, [arXiv:1906.11282].\n",
      "63. Anand, S.; Mahata, D.; Aggarwal, K.; Mehnaz, L.; Shahid, S.; Zhang, H.; Kumar, Y.; Shah, R.R.; Uppal, K.\n",
      "Suggestion Mining from Online Reviews using ULMFiT, 2019, [arXiv:1904.09076].\n",
      "64. Jeremy Howard, Sylvain Gugger, and contributors. SwiftAI . fast.ai, Inc, 2019.\n"
     ]
    }
   ],
   "source": [
    "print(pdf(Path('/home/nex/Downloads/ArXiv_Papers/2002.04688_fastai_A_Layered_API_for_Deep_Learning.pdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.data.transforms import RandomSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable function object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trn,val \u001b[38;5;241m=\u001b[39m RandomSplitter(\u001b[38;5;28mlist\u001b[39m(papers_vector))\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable function object"
     ]
    }
   ],
   "source": [
    "trn,val = RandomSplitter(list(papers_vector()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy\n",
    "# x is your dataset\n",
    "x = papers_vector\n",
    "def train_test_partition(X):\n",
    "  l = len(X)\n",
    "  l80porc = int(80 * l / 100)\n",
    "  numpy.random.shuffle(X)\n",
    "  training, test = X[:l80porc], X[l80porc:]\n",
    "  return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dataset():\n",
    "    return train_test_partition(papers_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
